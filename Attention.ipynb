{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3927e7bc",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5007e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58285d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getcwd() + os.sep + 'te' + os.sep + 'lexicons'\n",
    "train_path = dataset_path + os.sep + 'te.translit.sampled.train.tsv'\n",
    "valid_path = dataset_path + os.sep + 'te.translit.sampled.dev.tsv'\n",
    "test_path = dataset_path + os.sep + 'te.translit.sampled.test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6901b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "train_outputs = []\n",
    "valid_inputs = []\n",
    "valid_outputs = []\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "input_chars = set()\n",
    "output_chars = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad91d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748bb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "#     if not include_all and a!=1:\n",
    "#         continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    train_inputs.append(inp)\n",
    "    train_outputs.append(out)\n",
    "    for char in inp:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in out:\n",
    "        if char not in output_chars:\n",
    "            output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77599cd",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "58550"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d3b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(valid_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    valid_inputs.append(inp)\n",
    "    valid_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56668b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    test_inputs.append(inp)\n",
    "    test_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e91aed0",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "input_chars = sorted(list(input_chars))\n",
    "print(input_chars)\n",
    "num_input_chars = len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9618b73d",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\\t', '\\n', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '\\u200c']\n"
     ]
    }
   ],
   "source": [
    "output_chars = sorted(list(output_chars))\n",
    "print(output_chars)\n",
    "num_output_chars = len(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aacbd5e9",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25 21 23\n22\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_inputs)\n",
    "max_input_size = max([len(txt) for txt in train_inputs])\n",
    "max_valid_input_size = max([len(txt) for txt in valid_inputs])\n",
    "max_test_input_size = max([len(txt) for txt in test_inputs])\n",
    "print(max_input_size,max_valid_input_size,max_test_input_size)\n",
    "max_output_size = max([len(txt) for txt in  train_outputs])\n",
    "print(max_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56a8b966",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "input_index = dict([(char, i+1) for i, char in enumerate(input_chars)])\n",
    "output_index = dict([(char, i+1) for i, char in enumerate(output_chars)])\n",
    "print(input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba93c41e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'\\t': 1, '\\n': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
     ]
    }
   ],
   "source": [
    "print(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f8f0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Enoding in indexes of characters in the set\n",
    "def encode_index(inputs,index):\n",
    "    data = []\n",
    "    for i in range(len(inputs)):\n",
    "        a = np.zeros(len(inputs[i]))\n",
    "        j = 0\n",
    "        for char in inputs[i]:\n",
    "            a[j] = index[char]\n",
    "            j += 1\n",
    "        data.append(a)\n",
    "    data = np.asarray(data).astype(np.ndarray)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d8d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = []\n",
    "# for i in range(train_size):\n",
    "#     a = np.zeros(len(train_inputs[i]))\n",
    "#     j = 0\n",
    "#     for char in train_inputs[i]:\n",
    "#         a[j] = input_index[char]\n",
    "#         j += 1\n",
    "#     input_data.append(a)\n",
    "# input_data = np.asarray(input_data).astype(np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093d2dae",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "input_data = encode_index(train_inputs,input_index)\n",
    "input_tensor = tf.ragged.constant(input_data).to_tensor()\n",
    "\n",
    "val_input_data = encode_index(valid_inputs,input_index)\n",
    "val_input_tensor = tf.ragged.constant(val_input_data).to_tensor()\n",
    "\n",
    "test_input_data = encode_index(test_inputs,input_index)\n",
    "test_input_tensor = tf.ragged.constant(test_input_data).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62c961ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# input_tensor=input_tensor.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# val_input_tensor=val_input_tensor.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# test_input_tensor=test_input_tensor.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "953483ed",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "58550\n"
     ]
    }
   ],
   "source": [
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "350640cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val__input_size = max([len(txt) for txt in valid_inputs])\n",
    "max_val_output_size = max([len(txt) for txt in  valid_outputs])\n",
    "max_test_input_size = max([len(txt) for txt in test_inputs])\n",
    "max_test_output_size = max([len(txt) for txt in  test_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b26ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_output_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(train_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "# print(decoder_input_data[0])\n",
    "decoder_input_data = np.argmax(decoder_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_output_data = np.argmax(decoder_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_input_data = tf.convert_to_tensor(decoder_input_data)\n",
    "# decoder_output_data = tf.convert_to_tensor(decoder_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8681f530",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1.  5.  3. 18. 53. 32.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.]\n[ 1. 13. 11.  9. 20.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input_data[0])\n",
    "print(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_val_input_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_val_output_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(valid_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_val_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_val_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_val_input_data = np.argmax(decoder_val_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_output_data = np.argmax(decoder_val_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_input_data = tf.convert_to_tensor(decoder_val_input_data)\n",
    "# decoder_val_output_data = tf.convert_to_tensor(decoder_val_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52f20581",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_test_input_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_test_output_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(test_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_test_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_test_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_test_input_data = np.argmax(decoder_test_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_output_data = np.argmax(decoder_test_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_input_data = tf.convert_to_tensor(decoder_test_input_data)\n",
    "# decoder_test_output_data = tf.convert_to_tensor(decoder_test_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e50801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "# embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13b5339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(charinput,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b7e8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\"rmsprop\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "745cffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model.predict(input_data[0])\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66469fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "# x = K.placeholder(shape=(None, None, 2))\n",
    "# y = K.placeholder(shape=(2, 2))\n",
    "\n",
    "# print(K.dot(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751cf97",
   "metadata": {},
   "source": [
    "# Adding Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa2157e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb688c59",
   "metadata": {},
   "source": [
    "# Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b62a425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_model(input_embed_size , hidden_size):\n",
    "    charinput = tf.keras.Input(shape=(None,),dtype='float32',name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars+1,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    encoder = tf.keras.layers.LSTM(hidden_size, return_state=True,return_sequences=True )\n",
    "    encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1,64, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    print(encoder_outputs.shape)\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    dense_time = tf.keras.layers.TimeDistributed(decoder_dense, name='time_distributed_layer')\n",
    "#     decoder_pred = dense_time(decoder_concat_input)\n",
    "    \n",
    "    decoder_outputs = dense_time(decoder_concat_input)\n",
    "    \n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    \n",
    "    encoder_states_attn = [encoder_outputs,state_h,state_c]\n",
    "    encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "    # define inference decoder\n",
    "#     decoder_inf_out, decoder_inf_state = decoder_gru(decoder_inf_inputs, initial_state=decoder_init_state)\n",
    "#     attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "#     decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "#     decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "#     decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "#                           outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "    decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "    decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h,decoder_state_input_c]\n",
    "                                   , [decoder_outputs] + decoder_states + [attn_inf_states])\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d476dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_model, enc_model, dec_model = get_sample_model(16,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c71b19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_model.compile(\n",
    "#     optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "# sample_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cc12abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    sz  = input_seq.shape[0]\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    target_seq = np.zeros((sz,1,num_output_chars+1))\n",
    "    for i in range(sz):\n",
    "        target_seq[i, 0, output_index[\"\\t\"]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    decoded_seqs = [\"\" for i in range(sz)]\n",
    "    j = 0\n",
    "    while j < max_output_size:\n",
    "        output_tokens, h, c, attn = dec_model.predict([target_seq] + states_value)\n",
    "\n",
    "#         print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "        target_seq = np.zeros((sz, 1, num_output_chars+1))\n",
    "        for i in range(sz):\n",
    "            sampled_char = reverse_target_char_index[sampled_token_index[i]]\n",
    "            decoded_seqs[i] += sampled_char\n",
    "            target_seq[i, 0, sampled_token_index[i]] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        # Update states\n",
    "        states_value[1] = h\n",
    "        states_value[2] = c\n",
    "        j+=1\n",
    "    output = [ (\"\\t\"+st.split('\\n')[0]+\"\\n\") for st in decoded_seqs]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b557dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = input_tensor.to_tensor()\n",
    "# dec_model.run_eagerly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60cea938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seqid in range(10):\n",
    "#     input_seq = input_tensor[seqid:seqid+1]\n",
    "# #     print(input_seq.shape,input_tensor.shape)\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     print(\"-\")\n",
    "#     print(\"Input sentence:\", train_inputs[seqid])\n",
    "#     print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "962dfe8e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 25), dtype=float64, numpy=\n",
       "array([[ 1., 13., 11.,  9., 20.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "input_tensor[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83f42ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_model.fit(\n",
    "#     [input_tensor,decoder_input_data],\n",
    "#     decoder_output_data,\n",
    "#     batch_size=64,\n",
    "#     epochs=5,\n",
    "#     validation_data=([val_input_tensor,decoder_val_input_data],decoder_val_output_data),\n",
    "#     shuffle=True,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b5d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(data_tensor,data_output,k):\n",
    "#     crct = 0\n",
    "#     input_seq = data_tensor[:k]\n",
    "# #     print(input_seq.shape,input_tensor.shape)\n",
    "#     decoded_sentences = decode_sequence(input_seq)\n",
    "#     sts = data_output[:k]\n",
    "#     crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "# #         print(crct/(seqid+1))\n",
    "# #         for st,d in zip(sts,decoded_sentences):\n",
    "# #             print(st+\"_o\")\n",
    "# #             print(d+\"_o\")\n",
    "#     return crct/k,zip(decoded_sentences,sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42d57cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = evaluate(test_input_tensor,test_outputs,len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6acc5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_model.save('sample_attention'+os.sep+'model')\n",
    "# enc_model.save('sample_attention'+os.sep+'enc')\n",
    "# dec_model.save('sample_attention'+os.sep+'dec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a59bc",
   "metadata": {},
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20e8929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def beam_decode(input_seq, beam_size, enc_model, dec_model, cell_type):\n",
    "    sz  = input_seq.shape[0]\n",
    "    attention = []\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((sz,1,num_output_chars+1))\n",
    "    \n",
    "    for i in range(sz):\n",
    "        target_seq[i, 0, output_index[\"\\t\"]] = 1.0\n",
    "    \n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    decoded_seqs = [\"\" for i in range(sz)]\n",
    "    if cell_type == 'LSTM':\n",
    "        output_tokens, h, c, attn = dec_model.predict([target_seq] + states_value)\n",
    "        states = [states_value[0],h,c]\n",
    "        attention.append(attn)\n",
    "    if cell_type == 'GRU' or cell_type == 'RNN':\n",
    "        output_tokens, h, attn = dec_model.predict([target_seq] + states_value)\n",
    "        states = [states_value[0],h]\n",
    "        attention.append(attn)\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(sz):\n",
    "        sequences.append([])\n",
    "    sampled_token_beam = np.argpartition(output_tokens[:, -1, :], -beam_size ,axis=1)[:,-beam_size:]\n",
    "    sampled_token_indexes = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "    for i in range(sz):\n",
    "        allcandidates = list()\n",
    "        for j in range(beam_size):\n",
    "            allcandidates.append(\n",
    "                    [ [ sampled_token_beam[i][j] ],\n",
    "                        -np.log( \n",
    "                        output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                        states ,\n",
    "                        False])\n",
    "        ordered = sorted(allcandidates, key=lambda tup:tup[1])\n",
    "        sequences[i] = ordered[:beam_size]\n",
    "        \n",
    "    target_seq = np.zeros((sz, beam_size, num_output_chars+1))\n",
    "    for i in range(sz):\n",
    "        for j in range(beam_size): \n",
    "            target_seq[i, j, sequences[i][j][0][-1]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    it = 1\n",
    "    while it < max_output_size:\n",
    "        allcandidates = [list() for i in range(sz)]\n",
    "        for k in range(len(sequences[i])):\n",
    "            if cell_type == 'LSTM':\n",
    "                output_tokens, h, c, attn = dec_model.predict(\n",
    "                [target_seq[:,k]] + \n",
    "                sequences[i][k][2])\n",
    "                states = [states_value[0],h,c]\n",
    "                attention.append(attn)\n",
    "            if cell_type == 'GRU' or cell_type == 'RNN':\n",
    "                output_tokens, h, attn = dec_model.predict(\n",
    "                [target_seq[:,k]] + \n",
    "                sequences[i][k][2])\n",
    "                states = [states_value[0],h]\n",
    "                attention.append(attn)\n",
    "            sampled_token_beam = np.argpartition(output_tokens[:, -1, :], -beam_size ,axis=1)[:,-beam_size:]\n",
    "            sampled_token_indexes = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "            \n",
    "            for i in range(sz):\n",
    "                    if sequences[i][k][3]:\n",
    "                        allcandidates[i].append(\n",
    "                                [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                                 sequences[i][k][1],\n",
    "                                           states, True ])\n",
    "                        continue\n",
    "                    for j in range(beam_size):\n",
    "                        if reverse_target_char_index[sampled_token_beam[i][j]]=='\\n':\n",
    "                            allcandidates[i].append(\n",
    "                                [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                                 sequences[i][k][1]-np.log( \n",
    "                                     output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                                           states, True ])\n",
    "                        else:\n",
    "                            allcandidates[i].append(\n",
    "                            [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                             sequences[i][k][1]-np.log( \n",
    "                                 output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                                       states, False ])\n",
    "        for i in range(sz):\n",
    "            ordered = sorted(allcandidates[i], key=lambda tup:tup[1])\n",
    "            sequences[i] = ordered[:beam_size]\n",
    "        target_seq = np.zeros((sz, beam_size, num_output_chars+1))\n",
    "        for i in range(sz):\n",
    "            for j in range(beam_size): \n",
    "                target_seq[i, j, sequences[i][j][0][-1]] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        it+=1\n",
    "    output = []\n",
    "    for i in range(sz):\n",
    "        st = \"\"\n",
    "        for ind in sequences[i][0][0]:\n",
    "            st += reverse_target_char_index[ind]\n",
    "        output.append(\"\\t\"+st.split('\\n')[0]+\"\\n\")\n",
    "    return output , attention\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0075b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_evaluate(data_tensor,data_output,k,beam_size,enc_model, dec_model, cell_type):\n",
    "    crct = 0\n",
    "    input_seq = data_tensor[:k]\n",
    "    decoded_sentences, attention = beam_decode(input_seq,beam_size,enc_model, dec_model, cell_type)\n",
    "    sts = data_output[:k]\n",
    "    crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "    return crct/k,zip(decoded_sentences,sts),attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "540c2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1, b1, attention = beam_evaluate(test_input_tensor,test_outputs,len(test_outputs),1,enc_model,dec_model,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4883fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779eecba",
   "metadata": {},
   "source": [
    "# Attention color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "650b2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_evaluate_single(data_tensor,data_output,index,beam_size,enc_model, dec_model, cell_type):\n",
    "    crct = 0\n",
    "    input_seq = data_tensor[index:index+1]\n",
    "    decoded_sentences, attention = beam_decode(input_seq,beam_size,enc_model, dec_model, cell_type)\n",
    "    sts = data_output[index:index+1]\n",
    "    crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "    return crct,zip(decoded_sentences,sts),attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83b187dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # coding: utf-8\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# random_indexes = []\n",
    "# # outputs = []\n",
    "# # inputs = []\n",
    "# for i in range(9):\n",
    "#     a = np.random.randint(0,len(test_outputs))\n",
    "#     random_indexes.append(a)\n",
    "# fig = plt.figure(figsize = (15,15))\n",
    "# x = 1\n",
    "# for i in range(9):\n",
    "#     accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "#     # print(attention)\n",
    "#     attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "#     s = attention.shape\n",
    "#     attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "#     plt.subplot(3,3,x)\n",
    "#     # print(attention.shape,attention)\n",
    "#     for a, b in z:\n",
    "#         decoded_word = a[1:-1]\n",
    "#         expected_word = b \n",
    "#     input_word = test_inputs[random_indexes[i]]\n",
    "#     print(len(input_word),input_word)\n",
    "#     print(len(decoded_word),decoded_word)\n",
    "#     attention = attention[:len(decoded_word),:len(input_word)]\n",
    "#     print(attention)\n",
    "#     plt.imshow(attention,cmap='gray')\n",
    "#     font_prop = FontProperties(fname='Lohit-Telugu.ttf', size=18)\n",
    "   \n",
    "#     # plt.xlim(len(input_word))\n",
    "#     # plt.ylim(len(input_word))\n",
    "#     labels = []\n",
    "#     for s in decoded_word:\n",
    "#         labels.append(s)\n",
    "\n",
    "#     plt.yticks(range(len(labels)),labels,fontproperties = font_prop)\n",
    "#     plt.xticks(range(len(input_word)),input_word)\n",
    "#     x+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f1b6b",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d89312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textualheatmap import TextualHeatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "092e0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def data_string1(attention,output,input):\n",
    "    ## attention shape len(output) x len(input)  \n",
    "    data = []\n",
    "    dic_list = []\n",
    "    for i in range(len(output)):\n",
    "        l = []\n",
    "        a = []\n",
    "        for j in range(len(input)):\n",
    "            a.append((-math.log(attention[i][j]),input[j]))\n",
    "        a.sort()\n",
    "        m = []\n",
    "        for j in range(4):\n",
    "            if a[j][0] <= 3:\n",
    "                m.append(a[j][1])\n",
    "        d = dict()\n",
    "        d[\"token\"] =  output[i]\n",
    "        d[\"meta\"] = m\n",
    "        d[\"heat\"] = [1.0]\n",
    "        d1 = dict()\n",
    "        d1[\"token\"] = ' '\n",
    "        d1[\"format\"] = False\n",
    "        dic_list.append(d)\n",
    "        dic_list.append(d1)\n",
    "    data.append(dic_list)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "435c1148",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'\\t': 1, '\\n': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
     ]
    }
   ],
   "source": [
    "print(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec9bdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_string2(attention,output,input):\n",
    "    ## attention shape len(output) x len(input)  \n",
    "    data = []\n",
    "    dic_list = []\n",
    "    i = 0\n",
    "    while i < (len(output)):\n",
    "        token = output[i]\n",
    "        a = []\n",
    "        for j in range(len(input)):\n",
    "            a.append((-math.log(attention[i][j]),input[j]))\n",
    "        a.sort()\n",
    "        m = []\n",
    "        \n",
    "        mst = \"root: \"\n",
    "        for j in range(4):\n",
    "            if a[j][0] <= 3:\n",
    "                mst = mst + a[j][1] + \" \"\n",
    "        m.append(mst)\n",
    "        while(  ( (i+1)<len(output) ) and ( output_index[output[i+1]] < 5 or output_index[output[i+1]] > 51) ):\n",
    "            i+=1\n",
    "            token += output[i]\n",
    "            a = []\n",
    "            for j in range(len(input)):\n",
    "                a.append((-math.log(attention[i][j]),input[j]))\n",
    "            a.sort()\n",
    "            mst = output[i] + \": \"\n",
    "            for j in range(4):\n",
    "                if a[j][0] <= 3:\n",
    "                    mst = mst + a[j][1] + \" \"\n",
    "            m.append(mst)\n",
    "\n",
    "        d = dict()\n",
    "        d[\"token\"] =  token\n",
    "        d[\"meta\"] = m\n",
    "        d[\"heat\"] = [1.0]\n",
    "        d1 = dict()\n",
    "        d1[\"token\"] = ' '\n",
    "        d1[\"format\"] = True\n",
    "        dic_list.append(d)\n",
    "        i+=1\n",
    "        dic_list.append(d1)\n",
    "    data.append(dic_list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc1ec6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # coding: utf-8\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# random_indexes = []\n",
    "# # outputs = []\n",
    "# # inputs = []\n",
    "# for i in range(9):\n",
    "#     a = np.random.randint(0,len(test_outputs))\n",
    "#     random_indexes.append(a)\n",
    "# fig = plt.figure(figsize = (15,15))\n",
    "# x = 1\n",
    "# for i in range(1):\n",
    "#     accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "#     # print(attention)\n",
    "#     attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "#     s = attention.shape\n",
    "#     attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "#     # plt.subplot(3,3,x)\n",
    "#     # print(attention.shape,attention)\n",
    "#     for a, b in z:\n",
    "#         decoded_word = a[1:-1]\n",
    "#         expected_word = b \n",
    "#     input_word = test_inputs[random_indexes[i]]\n",
    "#     print(len(input_word),input_word)\n",
    "#     print(len(decoded_word),decoded_word)\n",
    "#     attention = attention[:len(decoded_word),:len(input_word)]\n",
    "#     data = data_string2(attention,decoded_word,input_word)\n",
    "#     print(data)\n",
    "#     heatmap = TextualHeatmap(facet_titles = ['Vis'], show_meta=True)\n",
    "#     heatmap.set_data(data)\n",
    "#     heatmap.highlight(159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e8b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d420bcfd",
   "metadata": {},
   "source": [
    "# Wandb Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10baf71d",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: mooizz (use `wandb login --relogin` to force relogin)\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\HP/.netrc\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login(key=\"866040d7d81f67025d43e7d50ecd83d54b6cf977\", relogin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "093bcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'val_word_accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "         'beam_size' : {\n",
    "            'values' : [1]\n",
    "        },\n",
    "        'input_embed_size': {\n",
    "            'values' : [16, 32, 64]\n",
    "        },\n",
    "        'hidden_size' : {\n",
    "            'values' : [128, 256, 512]\n",
    "        },\n",
    "        'cell_type' : {\n",
    "            'values' : ['GRU','LSTM','RNN']\n",
    "        },\n",
    "        'dropout' : {\n",
    "            'values' : [0, 0.2]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eab47e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ccz1whbm\n",
      "Sweep URL: https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"mooizz\",project=\"Rec_dakhashina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc7ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Model(input_embed_size , hidden_size, cell_type, dropout):\n",
    "    charinput = tf.keras.Input(shape=(None,),dtype='float32',name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars+1,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True )\n",
    "        encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    if cell_type == 'RNN':\n",
    "        encoder = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, return_state=True )\n",
    "        encoder_outputs, rnn_state = encoder(embedding)\n",
    "    if cell_type == 'GRU':\n",
    "        encoder = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True )\n",
    "        encoder_outputs, gru_state = encoder(embedding)\n",
    "        \n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1,64, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    if cell_type == 'RNN':\n",
    "        decoder_rnn = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _ = decoder_rnn(decoder_embedding, initial_state=rnn_state)\n",
    "    if cell_type == 'GRU':\n",
    "        decoder_gru = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=gru_state)\n",
    "    \n",
    "    # print(encoder_outputs.shape)\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    dense_time = tf.keras.layers.TimeDistributed(decoder_dense, name='time_distributed_layer')\n",
    "#     decoder_pred = dense_time(decoder_concat_input)\n",
    "    \n",
    "    decoder_outputs = dense_time(decoder_concat_input)\n",
    "    \n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    \n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder_states_attn = [encoder_outputs,state_h,state_c]\n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "        # define inference decoder\n",
    "    #     decoder_inf_out, decoder_inf_state = decoder_gru(decoder_inf_inputs, initial_state=decoder_init_state)\n",
    "    #     attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "    #     decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "    #     decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "    #     decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "    #                           outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
    "\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "        attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "        decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "        decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "        decoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h,decoder_state_input_c]\n",
    "                                       , [decoder_outputs] + decoder_states + [attn_inf_states])\n",
    "    if cell_type == 'GRU':\n",
    "        encoder_states_attn = [encoder_outputs,gru_state]\n",
    "        \n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "        \n",
    "        decoder_outputs, state_h = decoder_gru(decoder_embedding, initial_state=decoder_state_input_h)\n",
    "        attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "        decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "        decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "#         decoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h]\n",
    "                                       , [decoder_outputs] + [state_h] + [attn_inf_states])\n",
    "    if cell_type == 'RNN':\n",
    "        encoder_states_attn = [encoder_outputs,rnn_state]\n",
    "        \n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "        \n",
    "        decoder_outputs, state_h = decoder_rnn(decoder_embedding, initial_state=decoder_state_input_h)\n",
    "        attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "        decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "        decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "#         decoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h]\n",
    "                                       , [decoder_outputs] + [state_h] + [attn_inf_states])\n",
    "        \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52f0d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config_defaults = {\n",
    "        'epochs' : 20,\n",
    "        'batch_size' : 64,\n",
    "        'optimizer' : 'adam',\n",
    "        'beam_size' : 1,\n",
    "        'input_embed_size': 32,\n",
    "        'hidden_size' : 256,\n",
    "        'cell_type' : 'LSTM',\n",
    "        'dropout' : 0,\n",
    "    }\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    model, enc_model, dec_model = get_Model(config.input_embed_size,config.hidden_size,\n",
    "                     config.cell_type,\n",
    "                     config.dropout)\n",
    "    model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "#     sample_model.summary()\n",
    "    EarlyStopCB = tf.keras.callbacks.EarlyStopping(patience=30, monitor='val_accuracy',\n",
    "                                                  restore_best_weights=True)\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "    model.fit(\n",
    "        [input_tensor,decoder_input_data],\n",
    "        decoder_output_data,\n",
    "        batch_size=config.batch_size,\n",
    "        epochs=config.epochs,\n",
    "        validation_data=(\n",
    "            [val_input_tensor,decoder_val_input_data],\n",
    "            decoder_val_output_data\n",
    "        ),\n",
    "        shuffle=True,\n",
    "        callbacks=[WandbCallback(), EarlyStopCB])\n",
    "    beam_acc , _ , attention = beam_evaluate(val_input_tensor,valid_outputs,len(valid_outputs),config.beam_size,\n",
    "                                enc_model,\n",
    "                                dec_model,\n",
    "                                config.cell_type)\n",
    "    wandb.log({'val_word_accuracy' : beam_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e625837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 6o28he04 with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: GRU\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">exalted-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115436-6o28he04</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\exalted-sweep-1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\exalted-sweep-1\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19120<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115436-6o28he04\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115436-6o28he04\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>79</td></tr><tr><td>_timestamp</td><td>1621319155</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">exalted-sweep-1</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: kbbhtcbm with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: LSTM\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sunny-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115626-kbbhtcbm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\sunny-sweep-2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\sunny-sweep-2\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17376<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115626-kbbhtcbm\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115626-kbbhtcbm\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>77</td></tr><tr><td>_timestamp</td><td>1621319263</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sunny-sweep-2</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: asqtl5qt with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: RNN\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">leafy-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115817-asqtl5qt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\leafy-sweep-3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\leafy-sweep-3\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22420<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115817-asqtl5qt\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115817-asqtl5qt\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>79</td></tr><tr><td>_timestamp</td><td>1621319376</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">leafy-sweep-3</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "source": [
    "# Best Model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.21<br/>\n                Syncing run <strong style=\"color:#cdcd00\">resilient-wave-121</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n                Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/3n4exiwy\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/3n4exiwy</a><br/>\n                Run data is saved locally in <code>c:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210520_195708-3n4exiwy</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<h1>Run(3n4exiwy)</h1><iframe src=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/3n4exiwy\" style=\"border:none;width:100%;height:400px\"></iframe>",
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x11d67e9c780>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "wandb.init( entity=\"mooizz\",project=\"Rec_dakhashina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              [(None, None)]       0                                            \n__________________________________________________________________________________________________\ndecoder_input (InputLayer)      [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, None, 64)     1728        input[0][0]                      \n__________________________________________________________________________________________________\ndecoder_embedding (Embedding)   (None, None, 64)     4224        decoder_input[0][0]              \n__________________________________________________________________________________________________\nlstm (LSTM)                     [(None, None, 512),  1181696     embedding[0][0]                  \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, None, 512),  1181696     decoder_embedding[0][0]          \n                                                                 lstm[0][1]                       \n                                                                 lstm[0][2]                       \n__________________________________________________________________________________________________\nattention_layer (AttentionLayer ((None, None, 512),  524800      lstm[0][0]                       \n                                                                 lstm_1[0][0]                     \n__________________________________________________________________________________________________\nconcat_layer (Concatenate)      (None, None, 1024)   0           lstm_1[0][0]                     \n                                                                 attention_layer[0][0]            \n__________________________________________________________________________________________________\ntime_distributed_layer (TimeDis (None, None, 66)     67650       concat_layer[0][0]               \n==================================================================================================\nTotal params: 2,961,794\nTrainable params: 2,961,794\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model, enc_model, dec_model = get_Model(64,512,\n",
    "                     'LSTM',\n",
    "                     0.2)\n",
    "best_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n",
      "Epoch 1/10\n",
      "915/915 [==============================] - 2789s 3s/step - loss: 0.9435 - accuracy: 0.3361 - val_loss: 0.1522 - val_accuracy: 0.7891\n",
      "Epoch 2/10\n",
      "915/915 [==============================] - 2683s 3s/step - loss: 0.1213 - accuracy: 0.8197 - val_loss: 0.1088 - val_accuracy: 0.8181\n",
      "Epoch 3/10\n",
      "885/915 [============================>.] - ETA: 1:31 - loss: 0.0848 - accuracy: 0.8423"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-071db8e13296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         ),\n\u001b[0;32m     13\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         callbacks=[WandbCallback(), EarlyStopCB]) \n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    803\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1259\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3415\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3417\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3419\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[1;32m--> 757\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \"\"\"\n\u001b[0;32m    496\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 497\u001b[1;33m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[0;32m    498\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m       \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    439\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1692\u001b[0m   \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5526\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m   5527\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5528\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5529\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EarlyStopCB = tf.keras.callbacks.EarlyStopping(patience=30, monitor='val_accuracy',\n",
    "                                                  restore_best_weights=True)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "best_model.fit(\n",
    "        [input_tensor,decoder_input_data],\n",
    "        decoder_output_data,\n",
    "        batch_size=64,\n",
    "        epochs=1,\n",
    "        validation_data=(\n",
    "            [val_input_tensor,decoder_val_input_data],\n",
    "            decoder_val_output_data\n",
    "        ),\n",
    "        shuffle=True,\n",
    "        callbacks=[WandbCallback(), EarlyStopCB]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_acc , _ , attention = beam_evaluate(val_input_tensor,valid_outputs,len(valid_outputs),1,\n",
    "                                enc_model,\n",
    "                                dec_model,\n",
    "                                'LSTM')\n",
    "wandb.log({'val_word_accuracy' : beam_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-421556741774>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# inputs = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mrandom_indexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "random_indexes = []\n",
    "# outputs = []\n",
    "# inputs = []\n",
    "for i in range(9):\n",
    "    a = np.random.randint(0,len(test_outputs))\n",
    "    random_indexes.append(a)\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "x = 1\n",
    "for i in range(9):\n",
    "    accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "    # print(attention)\n",
    "    attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "    s = attention.shape\n",
    "    attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "    plt.subplot(3,3,x)\n",
    "    # print(attention.shape,attention)\n",
    "    for a, b in z:\n",
    "        decoded_word = a[1:-1]\n",
    "        expected_word = b \n",
    "    input_word = test_inputs[random_indexes[i]]\n",
    "    print(len(input_word),input_word)\n",
    "    print(len(decoded_word),decoded_word)\n",
    "    attention = attention[:len(decoded_word),:len(input_word)]\n",
    "    print(attention)\n",
    "    plt.imshow(attention,cmap='gray')\n",
    "    font_prop = FontProperties(fname='Lohit-Telugu.ttf', size=18)\n",
    "   \n",
    "    # plt.xlim(len(input_word))\n",
    "    # plt.ylim(len(input_word))\n",
    "    labels = []\n",
    "    for s in decoded_word:\n",
    "        labels.append(s)\n",
    "\n",
    "    plt.yticks(range(len(labels)),labels,fontproperties = font_prop)\n",
    "    plt.xticks(range(len(input_word)),input_word)\n",
    "    x+=1\n",
    "    \n",
    "wandb.log({\"heat_maps\":plt})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9 maatrices\n8 మాట్రిక్\n[[{'token': 'మా', 'meta': ['Core: m a ', 'ా: a t r a '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'ట్', 'meta': ['Core: r t ', '్: i c e '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'రి', 'meta': ['Core: i ', 'ి: c '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'క్', 'meta': ['Core: e c ', '్: s '], 'heat': [1.0]}, {'token': ' ', 'format': True}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"933adfc5-fb15-41ef-b574-3927750fca93\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"933adfc5-fb15-41ef-b574-3927750fca93\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9 jiraaphii\n6 జిరాఫీ\n[[{'token': 'జి', 'meta': ['Core: j i ', 'ి: r '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'రా', 'meta': ['Core: a r ', 'ా: a h p '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'ఫీ', 'meta': ['Core: h p ', 'ీ: i h i '], 'heat': [1.0]}, {'token': ' ', 'format': True}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"77c3a755-caec-4c78-8e16-5cf58ed539d9\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"77c3a755-caec-4c78-8e16-5cf58ed539d9\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 petteloe\n8 పెట్టెలో\n[[{'token': 'పె', 'meta': ['Core: p e ', 'ె: t t e e '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'ట్', 'meta': ['Core: t t e ', '్: e l t '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'టె', 'meta': ['Core: e l ', 'ె: l e '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'లో', 'meta': ['Core: l o e ', 'ో: e '], 'heat': [1.0]}, {'token': ' ', 'format': True}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"74aed3a5-ea83-48cc-869d-46cf22b59ddc\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"74aed3a5-ea83-48cc-869d-46cf22b59ddc\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6 cukiie\n6 క్యూకీ\n[[{'token': 'క్', 'meta': ['Core: u ', '్: k i c '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'యూ', 'meta': ['Core: i u k ', 'ూ: k c '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'కీ', 'meta': ['Core: i k e ', 'ీ: i '], 'heat': [1.0]}, {'token': ' ', 'format': True}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"b20c8819-bf14-486f-a998-a4a95dab22c0\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"b20c8819-bf14-486f-a998-a4a95dab22c0\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 enadu\n4 ఎనడు\n[[{'token': 'ఎ', 'meta': ['Core: e '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'న', 'meta': ['Core: a n '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'డు', 'meta': ['Core: d u ', 'ు: '], 'heat': [1.0]}, {'token': ' ', 'format': True}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"2498cbf9-4e3b-4e9b-ba54-f93e5a7e7c7b\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"2498cbf9-4e3b-4e9b-ba54-f93e5a7e7c7b\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "random_indexes = []\n",
    "# outputs = []\n",
    "# inputs = []\n",
    "for i in range(9):\n",
    "    a = np.random.randint(0,len(test_outputs))\n",
    "    random_indexes.append(a)\n",
    "# fig = plt.figure(figsize = (15,15))\n",
    "x = 1\n",
    "for i in range(5):\n",
    "    accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "    # print(attention)\n",
    "    attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "    s = attention.shape\n",
    "    attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "    # plt.subplot(3,3,x)\n",
    "    # print(attention.shape,attention)\n",
    "    for a, b in z:\n",
    "        decoded_word = a[1:-1]\n",
    "        expected_word = b \n",
    "    input_word = test_inputs[random_indexes[i]]\n",
    "    print(len(input_word),input_word)\n",
    "    print(len(decoded_word),decoded_word)\n",
    "    attention = attention[:len(decoded_word),:len(input_word)]\n",
    "    data = data_string2(attention,decoded_word,input_word)\n",
    "    print(data)\n",
    "    heatmap = TextualHeatmap(facet_titles = ['Vis'], show_meta=True)\n",
    "    heatmap.set_data(data)\n",
    "    heatmap.highlight(159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n",
      "6 darjee\n",
      "6 డార్జీ\n",
      "[[{'token': 'డ', 'meta': ['d', 'a'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ా', 'meta': ['r', 'j', 'd', 'a'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ర', 'meta': ['r', 'j'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': '్', 'meta': ['e'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'జ', 'meta': ['e', 'j'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ీ', 'meta': ['e'], 'heat': [1.0]}, {'token': ' ', 'format': False}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"abaae1e1-7c02-4b05-b5f1-f4c7ba03f0e1\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"abaae1e1-7c02-4b05-b5f1-f4c7ba03f0e1\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 heeroyin\n8 హీరోయిన్\n[[{'token': 'హ', 'meta': ['h', 'e'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ీ', 'meta': ['e', 'h', 'r', 'e'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ర', 'meta': ['r', 'o'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ో', 'meta': ['y'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'య', 'meta': ['y', 'i', 'n'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ి', 'meta': ['n'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'న', 'meta': ['n'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': '్', 'meta': [], 'heat': [1.0]}, {'token': ' ', 'format': False}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"a5f6b80a-6b20-445a-8bd3-f1e79fcfedfb\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"a5f6b80a-6b20-445a-8bd3-f1e79fcfedfb\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9 dopideeki\n8 దొపిదీకి\n[[{'token': 'ద', 'meta': ['d'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ొ', 'meta': ['p', 'i'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ప', 'meta': ['p', 'i'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ి', 'meta': ['d', 'i', 'e'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ద', 'meta': ['e', 'd'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ీ', 'meta': ['e', 'k', 'i'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'క', 'meta': ['i', 'k'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ి', 'meta': [], 'heat': [1.0]}, {'token': ' ', 'format': False}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"c14a9c45-7e75-451b-8d01-4f3d124f3da6\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"c14a9c45-7e75-451b-8d01-4f3d124f3da6\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10 gouthamudu\n7 గౌతముడు\n[[{'token': 'గ', 'meta': ['g', 'o'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ౌ', 'meta': ['u'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'త', 'meta': ['h'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'మ', 'meta': ['u', 'm'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ు', 'meta': ['d'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'డ', 'meta': ['u', 'd'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ు', 'meta': [], 'heat': [1.0]}, {'token': ' ', 'format': False}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"1d4708ab-98dc-4143-b794-7af97d9e29a1\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"1d4708ab-98dc-4143-b794-7af97d9e29a1\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13 sheershikaloo\n9 శీర్షికలో\n[[{'token': 'శ', 'meta': ['h', 'e'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ీ', 'meta': ['e', 's'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ర', 'meta': ['r', 's'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': '్', 'meta': ['h', 'i'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ష', 'meta': ['h'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ి', 'meta': ['k', 'l', 'i'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'క', 'meta': ['a', 'k'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ల', 'meta': ['l'], 'heat': [1.0]}, {'token': ' ', 'format': False}, {'token': 'ో', 'meta': ['o'], 'heat': [1.0]}, {'token': ' ', 'format': False}]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.textual-heatmap .facet {\n  display: grid;\n  grid-template-columns: 1fr 60px;\n  grid-template-rows: 40px auto;\n  grid-template-areas:\n    \"meta-content .\"\n    \"token-content facet-title\";\n  margin-bottom: 0.5em;\n}\n\n.textual-heatmap .facet.hide-meta-content {\n  grid-template-rows: auto;\n  grid-template-areas:\n    \"token-content facet-title\";\n}\n\n.textual-heatmap .facet .token-content {\n  grid-area: token-content;\n\n  font-family: monospace;\n  padding: 0.5em;\n  box-sizing: border-box;\n  background: #365d8d;\n  color: white;\n  line-height: 1.4em;\n  border-radius: 0 0 0 5px;\n}\n\n.textual-heatmap .facet.hide-meta-content .token-content {\n    border-radius: 5px 0 0 5px;\n}\n\n.textual-heatmap .facet .token-content span {\n  border-bottom: 0.2em solid transparent;\n  white-space: pre-wrap;\n}\n\n.textual-heatmap .facet .token-content span.selected {\n  border-bottom-color: white;\n}\n\n.textual-heatmap .facet .meta-content {\n  grid-area: meta-content;\n  display: grid;\n  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n  grid-column-gap: 2px;\n  align-items: center;\n}\n\n.textual-heatmap .facet.hide-meta-content .meta-content {\n    display: none;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item {\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  padding: 0 5px;\n  height: 39px;\n  background: #F3F3F3;\n  border: 1px solid #E0E0E0;\n  color: black;\n  border-bottom: none;\n  text-overflow: ellipsis;\n  overflow: hidden;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n    border-radius: 5px 0 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n    border-radius: 0 5px 0 0;\n}\n\n.textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n    border-radius: 5px 5px 0 0;\n}\n\n.textual-heatmap .facet .facet-title {\n  grid-area: facet-title;\n\n  display: flex;\n  max-width: 60px;\n  background: #EEEEEE;\n  justify-content: center;\n  color: #555555;\n  border-radius: 0 5px 5px 0;\n  border: 1px solid #E0E0E0;\n  border-left: none;\n}\n\n.textual-heatmap .facet .facet-title span {\n  align-self: center;\n  display: inline-block;\n  transform-origin: center center;\n  line-height: 1em;\n  text-align: center;\n}\n\n.textual-heatmap .facet.rotate-facet-title .facet-title span {\n  transform: translate(0, 0) rotate(90deg);\n}</style><script>;(function () {\n    'use strict';\n\n    function viridisSubset(ratio) {\n        const colormap = [\n            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n            '#34b679', '#35b779'\n        ];\n        const n = colormap.length - 1;\n        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n    }\n\n    class TextualHeatmap {\n        constructor(settings) {\n            this.container = document.getElementById(settings.id);\n            this.container.style.width = settings.width + 'px';\n            this.facets = settings.facetTitles\n                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].onmouseover = this.highlight.bind(this);\n            }\n        }\n\n        setData(data) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].setData(data[i]);\n            }\n        }\n\n        highlight(index) {\n            for (let i = 0; i < this.facets.length; i++) {\n                this.facets[i].highlight(index);\n            }\n        }\n    }\n\n    class TextualHeatmapFacet {\n        constructor(settings, root, facetName) {\n            this.settings = settings;\n            this.highlightIndex = null;\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = [];\n            this.root = root;\n            this.onmouseover = null;\n\n            this.facet = document.createElement('div');\n            this.facet.classList.add('facet');\n            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n            this.root.appendChild(this.facet);\n\n            this.meta = document.createElement('div');\n            this.meta.classList.add('meta-content');\n            this.facet.appendChild(this.meta);\n\n            const item = document.createElement('div');\n            item.classList.add('meta-content-item');\n            this.meta.appendChild(item);\n\n            this.content = document.createElement('div');\n            this.content.classList.add('token-content');\n            this.facet.appendChild(this.content);\n\n            this.title = document.createElement('div');\n            this.title.classList.add('facet-title');\n            const titleSpan = document.createElement('span');\n            titleSpan.appendChild(document.createTextNode(facetName));\n            this.title.appendChild(titleSpan);\n            this.facet.appendChild(this.title);\n        }\n\n        setData(data) {\n            this.nonFormatData = [];\n            this.heatIndexToNodeElement = []\n\n            while (this.content.childNodes.length > 0) {\n                this.content.removeChild(this.content.firstChild);\n            }\n\n            for (let i = 0; i < data.length; i++) {\n                const tokenNode = document.createElement('span');\n                const heatIndex = this.heatIndexToNodeElement.length;\n                tokenNode.appendChild(document.createTextNode(data[i].token));\n                if (this.settings.interactive && !data[i].format) {\n                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n                    this.heatIndexToNodeElement.push(tokenNode)\n                    this.nonFormatData.push(data[i])\n                }\n                this.content.appendChild(tokenNode);\n            }\n\n            if (this.highlightIndex !== null) {\n                this.highlight(this.highlightIndex);\n            }\n        }\n\n        highlight(index) {\n            this.highlightIndex = index;\n\n            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n            }\n\n            if (this.settings.showMeta) {\n                while (this.meta.childNodes.length > 0) {\n                    this.meta.removeChild(this.meta.firstChild);\n                }\n\n                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n                    this.meta.appendChild(item);\n                }\n\n                if (this.nonFormatData[index].meta.length === 0) {\n                    const item = document.createElement('div');\n                    item.classList.add('meta-content-item');\n                    this.meta.appendChild(item);\n                }\n            }\n        }\n    }\n\n    window.setupTextualHeatmap = function (settings) {\n        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n    };\n\n    window.setDataTextualHeatmap = function (settings, data) {\n        document.getElementById(settings.id).instance.setData(data);\n    };\n\n    window.highlightTextualHeatmap = function (settings, index) {\n        document.getElementById(settings.id).instance.highlight(index);\n    };\n})();</script><div id=\"0b898a78-e436-4c3f-8564-31226ad919fd\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"0b898a78-e436-4c3f-8564-31226ad919fd\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "void(0);"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "random_indexes = []\n",
    "# outputs = []\n",
    "# inputs = []\n",
    "for i in range(9):\n",
    "    a = np.random.randint(0,len(test_outputs))\n",
    "    random_indexes.append(a)\n",
    "# fig = plt.figure(figsize = (15,15))\n",
    "x = 1\n",
    "for i in range(5):\n",
    "    accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "    # print(attention)\n",
    "    attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "    s = attention.shape\n",
    "    attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "    # plt.subplot(3,3,x)\n",
    "    # print(attention.shape,attention)\n",
    "    for a, b in z:\n",
    "        decoded_word = a[1:-1]\n",
    "        expected_word = b \n",
    "    input_word = test_inputs[random_indexes[i]]\n",
    "    print(len(input_word),input_word)\n",
    "    print(len(decoded_word),decoded_word)\n",
    "    attention = attention[:len(decoded_word),:len(input_word)]\n",
    "    data = data_string1(attention,decoded_word,input_word)\n",
    "    print(data)\n",
    "    heatmap = TextualHeatmap(facet_titles = ['Vis'], show_meta=True)\n",
    "    heatmap.set_data(data)\n",
    "    heatmap.highlight(159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python370jvsc74a57bd0e2fb31f127fed1e79f709faf34890f85681c06e7e30d28a328e5c7500cdf6725",
   "display_name": "Python 3.7.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}