{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3927e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e5007e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58285d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getcwd() + os.sep + 'te' + os.sep + 'lexicons'\n",
    "train_path = dataset_path + os.sep + 'te.translit.sampled.train.tsv'\n",
    "valid_path = dataset_path + os.sep + 'te.translit.sampled.dev.tsv'\n",
    "test_path = dataset_path + os.sep + 'te.translit.sampled.test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6901b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "train_outputs = []\n",
    "valid_inputs = []\n",
    "valid_outputs = []\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "input_chars = set()\n",
    "output_chars = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dad91d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "748bb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "#     if not include_all and a!=1:\n",
    "#         continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    train_inputs.append(inp)\n",
    "    train_outputs.append(out)\n",
    "    for char in inp:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in out:\n",
    "        if char not in output_chars:\n",
    "            output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77599cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58550"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97d3b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(valid_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    valid_inputs.append(inp)\n",
    "    valid_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56668b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    test_inputs.append(inp)\n",
    "    test_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e91aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "input_chars = sorted(list(input_chars))\n",
    "print(input_chars)\n",
    "num_input_chars = len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9618b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '\\u200c']\n"
     ]
    }
   ],
   "source": [
    "output_chars = sorted(list(output_chars))\n",
    "print(output_chars)\n",
    "num_output_chars = len(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aacbd5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 21 23\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_inputs)\n",
    "max_input_size = max([len(txt) for txt in train_inputs])\n",
    "max_valid_input_size = max([len(txt) for txt in valid_inputs])\n",
    "max_test_input_size = max([len(txt) for txt in test_inputs])\n",
    "print(max_input_size,max_valid_input_size,max_test_input_size)\n",
    "max_output_size = max([len(txt) for txt in  train_outputs])\n",
    "print(max_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56a8b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "input_index = dict([(char, i+1) for i, char in enumerate(input_chars)])\n",
    "output_index = dict([(char, i+1) for i, char in enumerate(output_chars)])\n",
    "print(input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba93c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 1, '\\n': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
     ]
    }
   ],
   "source": [
    "print(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f8f0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Enoding in indexes of characters in the set\n",
    "def encode_index(inputs,index):\n",
    "    data = []\n",
    "    for i in range(len(inputs)):\n",
    "        a = np.zeros(len(inputs[i]))\n",
    "        j = 0\n",
    "        for char in inputs[i]:\n",
    "            a[j] = index[char]\n",
    "            j += 1\n",
    "        data.append(a)\n",
    "    data = np.asarray(data).astype(np.ndarray)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9d8d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = []\n",
    "# for i in range(train_size):\n",
    "#     a = np.zeros(len(train_inputs[i]))\n",
    "#     j = 0\n",
    "#     for char in train_inputs[i]:\n",
    "#         a[j] = input_index[char]\n",
    "#         j += 1\n",
    "#     input_data.append(a)\n",
    "# input_data = np.asarray(input_data).astype(np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "093d2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = encode_index(train_inputs,input_index)\n",
    "input_tensor = tf.ragged.constant(input_data).to_tensor()\n",
    "\n",
    "val_input_data = encode_index(valid_inputs,input_index)\n",
    "val_input_tensor = tf.ragged.constant(val_input_data).to_tensor()\n",
    "\n",
    "test_input_data = encode_index(test_inputs,input_index)\n",
    "test_input_tensor = tf.ragged.constant(test_input_data).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62c961ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# input_tensor=input_tensor.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# val_input_tensor=val_input_tensor.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# test_input_tensor=test_input_tensor.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "953483ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58550\n"
     ]
    }
   ],
   "source": [
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "350640cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val__input_size = max([len(txt) for txt in valid_inputs])\n",
    "max_val_output_size = max([len(txt) for txt in  valid_outputs])\n",
    "max_test_input_size = max([len(txt) for txt in test_inputs])\n",
    "max_test_output_size = max([len(txt) for txt in  test_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b26ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_output_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(train_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "# print(decoder_input_data[0])\n",
    "decoder_input_data = np.argmax(decoder_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_output_data = np.argmax(decoder_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_input_data = tf.convert_to_tensor(decoder_input_data)\n",
    "# decoder_output_data = tf.convert_to_tensor(decoder_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8681f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  5.  3. 18. 53. 32.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.]\n",
      "[ 1. 13. 11.  9. 20.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input_data[0])\n",
    "print(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d32549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_val_input_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_val_output_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(valid_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_val_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_val_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_val_input_data = np.argmax(decoder_val_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_output_data = np.argmax(decoder_val_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_input_data = tf.convert_to_tensor(decoder_val_input_data)\n",
    "# decoder_val_output_data = tf.convert_to_tensor(decoder_val_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52f20581",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_test_input_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_test_output_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(test_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_test_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_test_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_test_input_data = np.argmax(decoder_test_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_output_data = np.argmax(decoder_test_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_input_data = tf.convert_to_tensor(decoder_test_input_data)\n",
    "# decoder_test_output_data = tf.convert_to_tensor(decoder_test_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e50801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "# embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13b5339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(charinput,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b7e8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\"rmsprop\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "745cffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model.predict(input_data[0])\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66469fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "# x = K.placeholder(shape=(None, None, 2))\n",
    "# y = K.placeholder(shape=(2, 2))\n",
    "\n",
    "# print(K.dot(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751cf97",
   "metadata": {},
   "source": [
    "# Adding Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa2157e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb688c59",
   "metadata": {},
   "source": [
    "# Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b62a425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_model(input_embed_size , hidden_size):\n",
    "    charinput = tf.keras.Input(shape=(None,),dtype='float32',name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars+1,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    encoder = tf.keras.layers.LSTM(hidden_size, return_state=True,return_sequences=True )\n",
    "    encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1,64, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    print(encoder_outputs.shape)\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    dense_time = tf.keras.layers.TimeDistributed(decoder_dense, name='time_distributed_layer')\n",
    "#     decoder_pred = dense_time(decoder_concat_input)\n",
    "    \n",
    "    decoder_outputs = dense_time(decoder_concat_input)\n",
    "    \n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    \n",
    "    encoder_states_attn = [encoder_outputs,state_h,state_c]\n",
    "    encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "    # define inference decoder\n",
    "#     decoder_inf_out, decoder_inf_state = decoder_gru(decoder_inf_inputs, initial_state=decoder_init_state)\n",
    "#     attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "#     decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "#     decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "#     decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "#                           outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "    decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "    decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h,decoder_state_input_c]\n",
    "                                   , [decoder_outputs] + decoder_states + [attn_inf_states])\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d476dc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "# sample_model, enc_model, dec_model = get_sample_model(16,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c71b19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 16)     432         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 64)     4224        decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 128),  74240       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  98816       decoder_embedding[0][0]          \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 128),  32896       lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 256)    0           lstm_1[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_layer (TimeDis (None, None, 66)     16962       concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 227,570\n",
      "Trainable params: 227,570\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sample_model.compile(\n",
    "#     optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )\n",
    "# sample_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cc12abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    sz  = input_seq.shape[0]\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    target_seq = np.zeros((sz,1,num_output_chars+1))\n",
    "    for i in range(sz):\n",
    "        target_seq[i, 0, output_index[\"\\t\"]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    decoded_seqs = [\"\" for i in range(sz)]\n",
    "    j = 0\n",
    "    while j < max_output_size:\n",
    "        output_tokens, h, c, attn = dec_model.predict([target_seq] + states_value)\n",
    "\n",
    "#         print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "        target_seq = np.zeros((sz, 1, num_output_chars+1))\n",
    "        for i in range(sz):\n",
    "            sampled_char = reverse_target_char_index[sampled_token_index[i]]\n",
    "            decoded_seqs[i] += sampled_char\n",
    "            target_seq[i, 0, sampled_token_index[i]] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        # Update states\n",
    "        states_value[1] = h\n",
    "        states_value[2] = c\n",
    "        j+=1\n",
    "    output = [ (\"\\t\"+st.split('\\n')[0]+\"\\n\") for st in decoded_seqs]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b557dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = input_tensor.to_tensor()\n",
    "# dec_model.run_eagerly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60cea938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seqid in range(10):\n",
    "#     input_seq = input_tensor[seqid:seqid+1]\n",
    "# #     print(input_seq.shape,input_tensor.shape)\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     print(\"-\")\n",
    "#     print(\"Input sentence:\", train_inputs[seqid])\n",
    "#     print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "962dfe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 25), dtype=float64, numpy=\n",
       "array([[ 1., 13., 11.,  9., 20.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "input_tensor[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83f42ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "915/915 [==============================] - 118s 128ms/step - loss: 1.1435 - accuracy: 0.2262 - val_loss: 0.4755 - val_accuracy: 0.5939\n",
      "Epoch 2/5\n",
      "915/915 [==============================] - 116s 127ms/step - loss: 0.3481 - accuracy: 0.6791 - val_loss: 0.1866 - val_accuracy: 0.7686\n",
      "Epoch 3/5\n",
      "915/915 [==============================] - 120s 131ms/step - loss: 0.1702 - accuracy: 0.7892 - val_loss: 0.1427 - val_accuracy: 0.7987\n",
      "Epoch 4/5\n",
      "915/915 [==============================] - 114s 125ms/step - loss: 0.1301 - accuracy: 0.8142 - val_loss: 0.1269 - val_accuracy: 0.8071\n",
      "Epoch 5/5\n",
      "915/915 [==============================] - 115s 125ms/step - loss: 0.1104 - accuracy: 0.8259 - val_loss: 0.1185 - val_accuracy: 0.8116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc2e915cd0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_model.fit(\n",
    "#     [input_tensor,decoder_input_data],\n",
    "#     decoder_output_data,\n",
    "#     batch_size=64,\n",
    "#     epochs=5,\n",
    "#     validation_data=([val_input_tensor,decoder_val_input_data],decoder_val_output_data),\n",
    "#     shuffle=True,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(data_tensor,data_output,k):\n",
    "#     crct = 0\n",
    "#     input_seq = data_tensor[:k]\n",
    "# #     print(input_seq.shape,input_tensor.shape)\n",
    "#     decoded_sentences = decode_sequence(input_seq)\n",
    "#     sts = data_output[:k]\n",
    "#     crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "# #         print(crct/(seqid+1))\n",
    "# #         for st,d in zip(sts,decoded_sentences):\n",
    "# #             print(st+\"_o\")\n",
    "# #             print(d+\"_o\")\n",
    "#     return crct/k,zip(decoded_sentences,sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d57cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = evaluate(test_input_tensor,test_outputs,len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6acc5440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sample_attention\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sample_attention\\model\\assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sample_attention\\enc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sample_attention\\enc\\assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sample_attention\\dec\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sample_attention\\dec\\assets\n"
     ]
    }
   ],
   "source": [
    "# sample_model.save('sample_attention'+os.sep+'model')\n",
    "# enc_model.save('sample_attention'+os.sep+'enc')\n",
    "# dec_model.save('sample_attention'+os.sep+'dec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a59bc",
   "metadata": {},
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20e8929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def beam_decode(input_seq, beam_size, enc_model, dec_model, cell_type):\n",
    "    sz  = input_seq.shape[0]\n",
    "    attention = []\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((sz,1,num_output_chars+1))\n",
    "    \n",
    "    for i in range(sz):\n",
    "        target_seq[i, 0, output_index[\"\\t\"]] = 1.0\n",
    "    \n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    decoded_seqs = [\"\" for i in range(sz)]\n",
    "    if cell_type == 'LSTM':\n",
    "        output_tokens, h, c, attn = dec_model.predict([target_seq] + states_value)\n",
    "        states = [states_value[0],h,c]\n",
    "        attention.append(attn)\n",
    "    if cell_type == 'GRU' or cell_type == 'RNN':\n",
    "        output_tokens, h, attn = dec_model.predict([target_seq] + states_value)\n",
    "        states = [states_value[0],h]\n",
    "        attention.append(attn)\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(sz):\n",
    "        sequences.append([])\n",
    "    sampled_token_beam = np.argpartition(output_tokens[:, -1, :], -beam_size ,axis=1)[:,-beam_size:]\n",
    "    sampled_token_indexes = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "    for i in range(sz):\n",
    "        allcandidates = list()\n",
    "        for j in range(beam_size):\n",
    "            allcandidates.append(\n",
    "                    [ [ sampled_token_beam[i][j] ],\n",
    "                        -np.log( \n",
    "                        output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                        states ,\n",
    "                        False])\n",
    "        ordered = sorted(allcandidates, key=lambda tup:tup[1])\n",
    "        sequences[i] = ordered[:beam_size]\n",
    "        \n",
    "    target_seq = np.zeros((sz, beam_size, num_output_chars+1))\n",
    "    for i in range(sz):\n",
    "        for j in range(beam_size): \n",
    "            target_seq[i, j, sequences[i][j][0][-1]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    it = 1\n",
    "    while it < max_output_size:\n",
    "        allcandidates = [list() for i in range(sz)]\n",
    "        for k in range(len(sequences[i])):\n",
    "            if cell_type == 'LSTM':\n",
    "                output_tokens, h, c, attn = dec_model.predict(\n",
    "                [target_seq[:,k]] + \n",
    "                sequences[i][k][2])\n",
    "                states = [states_value[0],h,c]\n",
    "                attention.append(attn)\n",
    "            if cell_type == 'GRU' or cell_type == 'RNN':\n",
    "                output_tokens, h, attn = dec_model.predict(\n",
    "                [target_seq[:,k]] + \n",
    "                sequences[i][k][2])\n",
    "                states = [states_value[0],h]\n",
    "                attention.append(attn)\n",
    "            sampled_token_beam = np.argpartition(output_tokens[:, -1, :], -beam_size ,axis=1)[:,-beam_size:]\n",
    "            sampled_token_indexes = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "            \n",
    "            for i in range(sz):\n",
    "                    if sequences[i][k][3]:\n",
    "                        allcandidates[i].append(\n",
    "                                [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                                 sequences[i][k][1],\n",
    "                                           states, True ])\n",
    "                        continue\n",
    "                    for j in range(beam_size):\n",
    "                        if reverse_target_char_index[sampled_token_beam[i][j]]=='\\n':\n",
    "                            allcandidates[i].append(\n",
    "                                [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                                 sequences[i][k][1]-np.log( \n",
    "                                     output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                                           states, True ])\n",
    "                        else:\n",
    "                            allcandidates[i].append(\n",
    "                            [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                             sequences[i][k][1]-np.log( \n",
    "                                 output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                                       states, False ])\n",
    "        for i in range(sz):\n",
    "            ordered = sorted(allcandidates[i], key=lambda tup:tup[1])\n",
    "            sequences[i] = ordered[:beam_size]\n",
    "        target_seq = np.zeros((sz, beam_size, num_output_chars+1))\n",
    "        for i in range(sz):\n",
    "            for j in range(beam_size): \n",
    "                target_seq[i, j, sequences[i][j][0][-1]] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        it+=1\n",
    "    output = []\n",
    "    for i in range(sz):\n",
    "        st = \"\"\n",
    "        for ind in sequences[i][0][0]:\n",
    "            st += reverse_target_char_index[ind]\n",
    "        output.append(\"\\t\"+st.split('\\n')[0]+\"\\n\")\n",
    "    return output , attention\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0075b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_evaluate(data_tensor,data_output,k,beam_size,enc_model, dec_model, cell_type):\n",
    "    crct = 0\n",
    "    input_seq = data_tensor[:k]\n",
    "    decoded_sentences, attention = beam_decode(input_seq,beam_size,enc_model, dec_model, cell_type)\n",
    "    sts = data_output[:k]\n",
    "    crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "    return crct/k,zip(decoded_sentences,sts),attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "540c2082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# a1, b1, attention = beam_evaluate(test_input_tensor,test_outputs,len(test_outputs),1,enc_model,dec_model,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4883fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46720027840612494\n"
     ]
    }
   ],
   "source": [
    "# print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779eecba",
   "metadata": {},
   "source": [
    "# Attention color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "650b2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_evaluate_single(data_tensor,data_output,index,beam_size,enc_model, dec_model, cell_type):\n",
    "    crct = 0\n",
    "    input_seq = data_tensor[index:index+1]\n",
    "    decoded_sentences, attention = beam_decode(input_seq,beam_size,enc_model, dec_model, cell_type)\n",
    "    sts = data_output[index:index+1]\n",
    "    crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "    return crct,zip(decoded_sentences,sts),attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83b187dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 aandramu\n",
      "7 ఆంద్రము\n",
      "[[6.5350614e-02 9.3446630e-01 1.4319910e-04 2.1627482e-05 8.0658714e-07\n",
      "  4.4232751e-09 2.9313454e-09 4.2425832e-09]\n",
      " [3.1641062e-04 9.1521582e-03 3.3350298e-01 6.5154827e-01 2.8716431e-03\n",
      "  4.6354544e-06 2.2971817e-06 2.8873336e-07]\n",
      " [7.3303346e-07 2.9293347e-05 9.7381035e-03 9.8059958e-01 9.1390163e-03\n",
      "  1.1145668e-05 7.7697186e-06 1.8709642e-07]\n",
      " [5.8276037e-09 3.9343817e-08 3.5902383e-05 1.9486470e-02 4.2365569e-01\n",
      "  1.2654326e-02 1.5506032e-01 1.1907360e-02]\n",
      " [1.8680618e-10 2.6651135e-09 3.5101319e-05 1.2374687e-02 9.8592639e-01\n",
      "  2.5439393e-04 1.7668772e-04 6.2549002e-06]\n",
      " [2.8738809e-10 1.3757540e-09 6.0705311e-08 1.2175385e-04 2.4372658e-03\n",
      "  1.3641819e-02 9.4548941e-01 1.4739946e-02]\n",
      " [5.9942956e-10 1.4145404e-09 8.2285773e-10 1.2981945e-08 2.3876044e-06\n",
      "  1.8065619e-04 3.0923754e-02 7.7312922e-01]]\n",
      "7 chilchi\n",
      "6 చిల్చి\n",
      "[[1.4917266e-03 9.9834287e-01 1.5057543e-04 2.0004049e-06 5.5320004e-07\n",
      "  3.5271378e-07 5.9747428e-08]\n",
      " [8.2461024e-04 1.6349213e-03 3.2167491e-02 9.0594923e-01 8.7954523e-03\n",
      "  4.3179155e-03 2.3224278e-04]\n",
      " [3.2043047e-04 8.1155630e-04 2.4781760e-03 8.3033013e-01 3.9275564e-02\n",
      "  1.2127827e-01 2.8255017e-04]\n",
      " [2.7630614e-08 7.9942687e-08 2.0476446e-06 2.8729655e-02 5.8603102e-01\n",
      "  2.0379245e-01 1.2332820e-02]\n",
      " [1.1700984e-08 6.2115582e-08 2.9160494e-05 3.2862391e-02 4.1473454e-01\n",
      "  5.4999918e-01 1.0441216e-03]\n",
      " [6.6074213e-10 1.8786745e-09 7.4799704e-09 8.2013023e-05 2.2869110e-03\n",
      "  4.9048448e-03 2.6456889e-02]]\n",
      "9 sheshayya\n",
      "6 శేషయ్య\n",
      "[[4.46891859e-02 9.54912126e-01 9.53705239e-05 1.04546880e-05\n",
      "  1.21202038e-05 7.20541777e-08 7.83476963e-08 1.18130018e-07\n",
      "  1.23778356e-08]\n",
      " [6.82779355e-04 3.37455864e-03 1.15672804e-01 6.01718426e-01\n",
      "  2.59158194e-01 7.86486082e-04 3.46379122e-03 1.10093526e-04\n",
      "  5.03064530e-06]\n",
      " [6.82711470e-06 4.40207077e-05 5.61260327e-04 3.20602506e-01\n",
      "  6.75908327e-01 1.19290687e-03 7.05062877e-04 2.15445732e-04\n",
      "  3.60235708e-06]\n",
      " [6.42899622e-10 1.85892268e-09 3.23658007e-08 1.19645320e-05\n",
      "  3.46235931e-04 9.71116032e-03 8.53037417e-01 1.07190706e-01\n",
      "  9.83398757e-04]\n",
      " [1.24665767e-09 2.53302490e-09 2.40647702e-09 1.65839111e-08\n",
      "  1.75915943e-07 5.53619066e-06 5.10909944e-04 3.64264846e-01\n",
      "  1.84525363e-02]\n",
      " [2.23216081e-11 1.71956602e-10 1.05308517e-08 1.94083668e-06\n",
      "  1.38492715e-05 8.72902339e-04 1.99617818e-02 9.73461986e-01\n",
      "  3.04233539e-03]]\n",
      "7 jaavaed\n",
      "6 జావేద్\n",
      "[[9.9656290e-01 1.9485959e-04 4.2954209e-04 7.5679882e-06 1.2148216e-07\n",
      "  2.4123833e-07 3.9454477e-07]\n",
      " [2.8303536e-03 2.0612963e-02 6.4980382e-01 2.9315445e-01 3.4565761e-04\n",
      "  6.4961473e-04 2.8872690e-03]\n",
      " [1.9160387e-04 2.0646560e-03 2.6842056e-02 9.4966751e-01 2.4726102e-04\n",
      "  3.5515206e-04 9.9683972e-03]\n",
      " [5.6006872e-08 2.5290517e-06 1.0970064e-04 1.9058060e-03 3.7004326e-03\n",
      "  6.6003275e-01 2.9249808e-01]\n",
      " [9.0178290e-08 3.1516722e-06 2.9025692e-05 7.5603829e-04 5.2112708e-04\n",
      "  6.1709429e-03 9.6888977e-01]\n",
      " [1.2181537e-09 6.1963923e-09 4.9073932e-08 4.9788133e-07 9.8864928e-07\n",
      "  2.5809306e-05 1.1900111e-02]]\n",
      "8 degreela\n",
      "7 దెగ్రీల\n",
      "[[9.9075729e-01 1.3740027e-03 1.6846358e-03 5.5727698e-05 2.1574742e-06\n",
      "  1.3394406e-07 7.7643665e-07 2.6147918e-06]\n",
      " [1.0363645e-03 7.1657807e-02 8.3462781e-01 4.3054791e-03 1.2577295e-03\n",
      "  1.1485505e-04 2.9191902e-04 2.1920239e-05]\n",
      " [1.6849184e-04 1.1261418e-03 9.7486973e-01 1.7250497e-02 9.3395164e-04\n",
      "  9.4106137e-05 2.7169034e-04 1.4963633e-05]\n",
      " [2.0902473e-07 1.6397094e-05 2.4526510e-02 4.7816738e-01 6.0613770e-02\n",
      "  2.5913829e-02 3.4938477e-02 2.8915444e-04]\n",
      " [1.0605265e-07 4.7788166e-05 6.6381395e-02 9.1701806e-01 3.6179775e-03\n",
      "  1.1956109e-04 3.2200615e-03 6.7286928e-05]\n",
      " [8.9084934e-10 2.1808003e-08 1.2629693e-04 8.0484189e-03 6.7984402e-02\n",
      "  7.5766134e-01 8.6038657e-02 2.8839655e-04]\n",
      " [1.8960706e-09 1.6034550e-08 3.4320245e-05 2.1558881e-03 1.4234527e-03\n",
      "  2.3492137e-02 9.5956933e-01 4.2484012e-03]]\n",
      "14 uparitalaaniki\n",
      "11 ఉపరితలానికి\n",
      "[[9.99696732e-01 3.34475953e-05 1.14518905e-07 3.07039841e-07\n",
      "  1.21855237e-07 6.42322391e-08 3.31754180e-08 3.16320659e-08\n",
      "  8.60117666e-08 4.85906710e-08 7.17809954e-08 3.50881663e-07\n",
      "  2.22514398e-08 3.35735734e-07]\n",
      " [6.77969679e-03 9.43822861e-01 8.20404757e-03 2.71248538e-02\n",
      "  2.17754045e-04 6.10294344e-04 1.69375835e-05 5.65588198e-06\n",
      "  1.22277897e-05 3.80473034e-06 1.69672512e-05 9.40158861e-06\n",
      "  3.79625999e-06 6.37442872e-06]\n",
      " [5.78297950e-05 2.30607740e-03 3.18573904e-03 9.20708895e-01\n",
      "  2.78303749e-03 3.00916415e-02 1.53181245e-05 2.80458422e-04\n",
      "  2.13906405e-05 1.00975285e-05 9.37143886e-06 6.22554126e-06\n",
      "  1.27280164e-05 5.09770462e-06]\n",
      " [2.25419026e-08 3.12633404e-08 1.17477875e-07 4.22430836e-04\n",
      "  2.18315981e-02 8.42933834e-01 6.05304842e-04 8.58879462e-02\n",
      "  4.50557018e-05 1.66299520e-04 2.82929948e-04 4.27432315e-05\n",
      "  8.15770036e-05 1.40058737e-05]\n",
      " [4.35984512e-11 1.27953217e-10 5.54360646e-09 3.02908320e-05\n",
      "  7.58470618e-04 9.93281603e-01 3.79748642e-04 4.22721542e-03\n",
      "  2.48215019e-05 5.33118146e-06 3.87542386e-05 3.97043641e-06\n",
      "  1.27186222e-05 2.26180759e-06]\n",
      " [1.57011237e-10 2.02490080e-10 6.29541086e-10 9.37136377e-08\n",
      "  1.32385924e-06 7.94162217e-04 7.12726079e-03 9.33601856e-01\n",
      "  1.37356145e-03 2.03366801e-02 1.96503829e-02 1.19682874e-04\n",
      "  4.41023702e-04 1.82382446e-05]\n",
      " [5.92973309e-11 5.58242376e-11 7.18026125e-11 2.22486016e-10\n",
      "  1.76381099e-09 1.87101170e-06 9.36560082e-06 8.73710867e-03\n",
      "  4.35537212e-02 7.97973335e-01 1.25819236e-01 3.11329868e-03\n",
      "  1.24079324e-02 1.35670445e-04]\n",
      " [4.14646724e-13 2.30163306e-12 1.11915598e-11 6.60747498e-12\n",
      "  2.78040396e-10 1.17597425e-08 5.39266637e-07 4.79587074e-03\n",
      "  1.04400506e-02 3.42929326e-02 9.07984555e-01 6.41549146e-03\n",
      "  2.37648543e-02 8.30972102e-04]\n",
      " [3.87466365e-10 2.09132101e-10 2.50837906e-10 2.12937404e-10\n",
      "  4.01061934e-10 3.94513799e-09 3.96631101e-08 1.61984222e-04\n",
      "  3.95182782e-04 6.43257936e-03 1.77750885e-02 1.96790770e-02\n",
      "  8.94086003e-01 4.98587172e-03]\n",
      " [8.91411858e-12 3.44600182e-11 2.14657625e-10 9.73580105e-11\n",
      "  3.36117884e-10 4.54624649e-09 5.34239284e-08 3.05464600e-05\n",
      "  1.25938186e-05 4.47826133e-05 1.61496410e-03 3.94874049e-04\n",
      "  9.66192722e-01 1.27713254e-03]\n",
      " [4.67111183e-10 3.55599467e-10 3.63592989e-10 2.01046915e-10\n",
      "  3.33605255e-10 1.75069259e-09 2.19142926e-09 3.43328736e-07\n",
      "  1.02833394e-04 8.79253668e-04 2.47549871e-03 8.43260344e-03\n",
      "  1.84366088e-02 7.10835308e-02]]\n",
      "9 septembar\n",
      "10 సెప్టెంబర్\n",
      "[[9.8501056e-01 9.3003307e-03 1.2129593e-04 5.5592354e-05 3.4294378e-06\n",
      "  4.7053654e-06 4.6515615e-06 1.8985902e-06 1.0667304e-06]\n",
      " [1.2420560e-03 3.4696914e-02 8.5859185e-01 3.3372849e-02 6.8630540e-04\n",
      "  1.9124284e-03 1.1895519e-03 2.3568102e-05 1.7788898e-05]\n",
      " [3.7376518e-05 1.1882233e-03 6.4026588e-01 2.6482901e-01 1.4432619e-02\n",
      "  2.4992110e-02 4.2642644e-03 5.1122828e-05 3.0936350e-05]\n",
      " [3.9606554e-08 2.1996636e-06 3.5809998e-03 4.0038648e-01 5.7544716e-02\n",
      "  3.7813306e-01 5.4382421e-02 2.0120306e-04 1.0512213e-03]\n",
      " [2.2246073e-08 7.1628392e-06 8.6077163e-03 9.2021507e-01 3.1122994e-02\n",
      "  2.0102315e-02 1.4090270e-02 2.5059009e-05 1.3972972e-05]\n",
      " [5.5835403e-10 4.3708361e-09 4.5382094e-06 8.4444592e-03 3.5516407e-02\n",
      "  6.3281190e-01 1.7335044e-01 3.3785263e-03 4.5436013e-02]\n",
      " [2.6867428e-10 2.0653645e-09 8.7741466e-07 6.6291814e-04 7.1074092e-04\n",
      "  6.1308479e-01 3.4267220e-01 2.4536408e-03 1.3573735e-02]\n",
      " [1.9204454e-12 1.3439391e-11 1.0039669e-09 1.9132223e-05 3.1016421e-05\n",
      "  2.1575851e-02 9.3559724e-01 1.0754742e-02 1.1553887e-02]\n",
      " [1.6552891e-11 1.7880983e-11 8.5731124e-11 1.5969478e-08 3.8999442e-08\n",
      "  7.4016723e-05 1.9725761e-03 3.3759112e-03 8.8353491e-01]\n",
      " [2.7588603e-08 4.2885766e-08 8.3396770e-08 2.4232830e-07 4.3888394e-07\n",
      "  2.4930610e-05 1.4255837e-03 1.1181050e-03 5.2637637e-02]]\n",
      "8 arthamlo\n",
      "7 అర్థంలో\n",
      "[[9.94455636e-01 4.70041996e-03 1.36191748e-05 2.21187565e-05\n",
      "  8.51016637e-07 3.93470259e-07 3.84775802e-07 9.10895096e-07]\n",
      " [9.59316618e-04 9.09620762e-01 5.73637821e-02 2.47920044e-02\n",
      "  8.11657810e-05 9.81455232e-05 2.57751872e-05 3.69648333e-05]\n",
      " [1.91470554e-06 1.59051456e-03 4.61668134e-01 3.41017455e-01\n",
      "  1.92517426e-03 6.43833205e-02 9.19657946e-03 2.54613638e-04]\n",
      " [1.60928732e-06 2.27650721e-03 2.52274692e-01 7.42670476e-01\n",
      "  3.42703774e-04 7.63324933e-05 2.98545579e-04 2.28674053e-05]\n",
      " [8.74920275e-11 1.25072352e-08 7.48669321e-04 4.41931072e-04\n",
      "  5.89413987e-03 8.68609548e-01 1.03422634e-01 8.60753702e-04]\n",
      " [4.46075555e-12 1.19788457e-10 3.81650307e-06 4.08099777e-06\n",
      "  2.39513131e-04 3.37902457e-03 9.24038768e-01 6.59686774e-02]\n",
      " [1.39654694e-11 2.06777703e-11 6.94802382e-10 6.99988734e-10\n",
      "  1.28158710e-08 2.48480683e-05 3.63012194e-03 9.25725222e-01]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 grahastula\n",
      "9 గ్రహస్తుల\n",
      "[[9.9678373e-01 8.8575407e-04 1.3771403e-06 1.2792134e-06 4.5588834e-07\n",
      "  5.3986963e-07 1.1632461e-06 6.9377182e-07 2.3409821e-06 1.6750920e-06]\n",
      " [2.7760388e-03 3.4349343e-01 1.8271847e-02 9.1252059e-02 3.8374132e-03\n",
      "  3.4561709e-03 1.6011521e-03 8.0101675e-04 5.4740475e-04 1.1734154e-04]\n",
      " [1.8357746e-02 8.8518906e-01 1.0827223e-03 5.0027960e-04 6.5259337e-05\n",
      "  1.3473188e-04 2.0345593e-04 1.7413638e-05 4.3560449e-05 4.3508218e-05]\n",
      " [1.2914461e-05 3.2980093e-03 2.6758995e-02 9.3342018e-01 9.0990812e-03\n",
      "  2.3678349e-02 6.1919732e-04 1.7380133e-05 2.3323032e-06 1.6058841e-07]\n",
      " [3.1296095e-09 6.1117767e-06 3.1188716e-05 4.7876062e-03 1.0763818e-02\n",
      "  8.6475277e-01 5.1866710e-02 2.6443659e-03 2.3206339e-04 1.8491308e-05]\n",
      " [2.2988782e-09 1.0574094e-08 9.0659228e-08 8.3861318e-07 1.1899975e-05\n",
      "  2.3060634e-03 9.1122419e-01 3.9431747e-02 4.7446582e-03 4.2605338e-05]\n",
      " [7.7426870e-11 3.0324543e-08 2.3998084e-07 4.9843334e-06 7.8927114e-05\n",
      "  7.1400385e-03 9.8434389e-01 2.2007606e-03 3.8830454e-03 3.9726052e-05]\n",
      " [1.6241498e-10 3.9922485e-10 1.8858239e-09 8.6944683e-09 2.1471918e-07\n",
      "  2.7114642e-04 6.5807454e-02 6.9535136e-01 1.6269213e-01 4.7164285e-04]\n",
      " [7.2366758e-11 8.4066122e-11 5.3469346e-10 1.9515040e-10 2.3735898e-09\n",
      "  2.3617110e-07 1.9973647e-03 3.7024799e-03 9.8164970e-01 4.2514084e-03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:240: RuntimeWarning: Glyph 108 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:240: RuntimeWarning: Glyph 112 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # coding: utf-8\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# random_indexes = []\n",
    "# # outputs = []\n",
    "# # inputs = []\n",
    "# for i in range(9):\n",
    "#     a = np.random.randint(0,len(test_outputs))\n",
    "#     random_indexes.append(a)\n",
    "# fig = plt.figure(figsize = (15,15))\n",
    "# x = 1\n",
    "# for i in range(9):\n",
    "#     accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "#     # print(attention)\n",
    "#     attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "#     s = attention.shape\n",
    "#     attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "#     plt.subplot(3,3,x)\n",
    "#     # print(attention.shape,attention)\n",
    "#     for a, b in z:\n",
    "#         decoded_word = a[1:-1]\n",
    "#         expected_word = b \n",
    "#     input_word = test_inputs[random_indexes[i]]\n",
    "#     print(len(input_word),input_word)\n",
    "#     print(len(decoded_word),decoded_word)\n",
    "#     attention = attention[:len(decoded_word),:len(input_word)]\n",
    "#     print(attention)\n",
    "#     plt.imshow(attention,cmap='gray')\n",
    "#     font_prop = FontProperties(fname='Lohit-Telugu.ttf', size=18)\n",
    "   \n",
    "#     # plt.xlim(len(input_word))\n",
    "#     # plt.ylim(len(input_word))\n",
    "#     labels = []\n",
    "#     for s in decoded_word:\n",
    "#         labels.append(s)\n",
    "\n",
    "#     plt.yticks(range(len(labels)),labels,fontproperties = font_prop)\n",
    "#     plt.xticks(range(len(input_word)),input_word)\n",
    "#     x+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f1b6b",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d89312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textualheatmap import TextualHeatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "092e0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def data_string1(attention,output,input):\n",
    "    ## attention shape len(output) x len(input)  \n",
    "    data = []\n",
    "    dic_list = []\n",
    "    for i in range(len(output)):\n",
    "        l = []\n",
    "        a = []\n",
    "        for j in range(len(input)):\n",
    "            a.append((-math.log(attention[i][j]),input[j]))\n",
    "        a.sort()\n",
    "        m = []\n",
    "        for j in range(4):\n",
    "            if a[j][0] <= 3:\n",
    "                m.append(a[j][1])\n",
    "        d = dict()\n",
    "        d[\"token\"] =  output[i]\n",
    "        d[\"meta\"] = m\n",
    "        d[\"heat\"] = [1.0]\n",
    "        d1 = dict()\n",
    "        d1[\"token\"] = ' '\n",
    "        d1[\"format\"] = False\n",
    "        dic_list.append(d)\n",
    "        dic_list.append(d1)\n",
    "    data.append(dic_list)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "435c1148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 1, '\\n': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
     ]
    }
   ],
   "source": [
    "print(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec9bdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_string2(attention,output,input):\n",
    "    ## attention shape len(output) x len(input)  \n",
    "    data = []\n",
    "    dic_list = []\n",
    "    i = 0\n",
    "    while i < (len(output)):\n",
    "        token = output[i]\n",
    "        a = []\n",
    "        for j in range(len(input)):\n",
    "            a.append((-math.log(attention[i][j]),input[j]))\n",
    "        a.sort()\n",
    "        m = []\n",
    "        \n",
    "        mst = \"Core: \"\n",
    "        for j in range(4):\n",
    "            if a[j][0] <= 3:\n",
    "                mst = mst + a[j][1] + \" \"\n",
    "        m.append(mst)\n",
    "        while(  ( (i+1)<len(output) ) and ( output_index[output[i+1]] < 5 or output_index[output[i+1]] > 51) ):\n",
    "            i+=1\n",
    "            token += output[i]\n",
    "            a = []\n",
    "            for j in range(len(input)):\n",
    "                a.append((-math.log(attention[i][j]),input[j]))\n",
    "            a.sort()\n",
    "            mst = output[i] + \": \"\n",
    "            for j in range(4):\n",
    "                if a[j][0] <= 3:\n",
    "                    mst = mst + a[j][1] + \" \"\n",
    "            m.append(mst)\n",
    "\n",
    "        d = dict()\n",
    "        d[\"token\"] =  token\n",
    "        d[\"meta\"] = m\n",
    "        d[\"heat\"] = [1.0]\n",
    "        d1 = dict()\n",
    "        d1[\"token\"] = ' '\n",
    "        d1[\"format\"] = True\n",
    "        dic_list.append(d)\n",
    "        i+=1\n",
    "        dic_list.append(d1)\n",
    "    data.append(dic_list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc1ec6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 chinnadi\n",
      "7 చిన్నడి\n",
      "[[{'token': 'చి', 'meta': ['Core: h ', 'ి: n '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'న్', 'meta': ['Core: n n ', '్: n d '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'న', 'meta': ['Core: n n '], 'heat': [1.0]}, {'token': ' ', 'format': True}, {'token': 'డి', 'meta': ['Core: d ', 'ి: i '], 'heat': [1.0]}, {'token': ' ', 'format': True}]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.textual-heatmap .facet {\n",
       "  display: grid;\n",
       "  grid-template-columns: 1fr 60px;\n",
       "  grid-template-rows: 40px auto;\n",
       "  grid-template-areas:\n",
       "    \"meta-content .\"\n",
       "    \"token-content facet-title\";\n",
       "  margin-bottom: 0.5em;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.hide-meta-content {\n",
       "  grid-template-rows: auto;\n",
       "  grid-template-areas:\n",
       "    \"token-content facet-title\";\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .token-content {\n",
       "  grid-area: token-content;\n",
       "\n",
       "  font-family: monospace;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  background: #365d8d;\n",
       "  color: white;\n",
       "  line-height: 1.4em;\n",
       "  border-radius: 0 0 0 5px;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.hide-meta-content .token-content {\n",
       "    border-radius: 5px 0 0 5px;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .token-content span {\n",
       "  border-bottom: 0.2em solid transparent;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .token-content span.selected {\n",
       "  border-bottom-color: white;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content {\n",
       "  grid-area: meta-content;\n",
       "  display: grid;\n",
       "  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n",
       "  grid-column-gap: 2px;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.hide-meta-content .meta-content {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item {\n",
       "  display: flex;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "  padding: 0 5px;\n",
       "  height: 39px;\n",
       "  background: #F3F3F3;\n",
       "  border: 1px solid #E0E0E0;\n",
       "  color: black;\n",
       "  border-bottom: none;\n",
       "  text-overflow: ellipsis;\n",
       "  overflow: hidden;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n",
       "    border-radius: 5px 0 0 0;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n",
       "    border-radius: 0 5px 0 0;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n",
       "    border-radius: 5px 5px 0 0;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .facet-title {\n",
       "  grid-area: facet-title;\n",
       "\n",
       "  display: flex;\n",
       "  max-width: 60px;\n",
       "  background: #EEEEEE;\n",
       "  justify-content: center;\n",
       "  color: #555555;\n",
       "  border-radius: 0 5px 5px 0;\n",
       "  border: 1px solid #E0E0E0;\n",
       "  border-left: none;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .facet-title span {\n",
       "  align-self: center;\n",
       "  display: inline-block;\n",
       "  transform-origin: center center;\n",
       "  line-height: 1em;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.rotate-facet-title .facet-title span {\n",
       "  transform: translate(0, 0) rotate(90deg);\n",
       "}</style><script>;(function () {\n",
       "    'use strict';\n",
       "\n",
       "    function viridisSubset(ratio) {\n",
       "        const colormap = [\n",
       "            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n",
       "            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n",
       "            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n",
       "            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n",
       "            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n",
       "            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n",
       "            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n",
       "            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n",
       "            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n",
       "            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n",
       "            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n",
       "            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n",
       "            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n",
       "            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n",
       "            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n",
       "            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n",
       "            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n",
       "            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n",
       "            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n",
       "            '#34b679', '#35b779'\n",
       "        ];\n",
       "        const n = colormap.length - 1;\n",
       "        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n",
       "    }\n",
       "\n",
       "    class TextualHeatmap {\n",
       "        constructor(settings) {\n",
       "            this.container = document.getElementById(settings.id);\n",
       "            this.container.style.width = settings.width + 'px';\n",
       "            this.facets = settings.facetTitles\n",
       "                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n",
       "\n",
       "            for (let i = 0; i < this.facets.length; i++) {\n",
       "                this.facets[i].onmouseover = this.highlight.bind(this);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        setData(data) {\n",
       "            for (let i = 0; i < this.facets.length; i++) {\n",
       "                this.facets[i].setData(data[i]);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        highlight(index) {\n",
       "            for (let i = 0; i < this.facets.length; i++) {\n",
       "                this.facets[i].highlight(index);\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "\n",
       "    class TextualHeatmapFacet {\n",
       "        constructor(settings, root, facetName) {\n",
       "            this.settings = settings;\n",
       "            this.highlightIndex = null;\n",
       "            this.nonFormatData = [];\n",
       "            this.heatIndexToNodeElement = [];\n",
       "            this.root = root;\n",
       "            this.onmouseover = null;\n",
       "\n",
       "            this.facet = document.createElement('div');\n",
       "            this.facet.classList.add('facet');\n",
       "            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n",
       "            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n",
       "            this.root.appendChild(this.facet);\n",
       "\n",
       "            this.meta = document.createElement('div');\n",
       "            this.meta.classList.add('meta-content');\n",
       "            this.facet.appendChild(this.meta);\n",
       "\n",
       "            const item = document.createElement('div');\n",
       "            item.classList.add('meta-content-item');\n",
       "            this.meta.appendChild(item);\n",
       "\n",
       "            this.content = document.createElement('div');\n",
       "            this.content.classList.add('token-content');\n",
       "            this.facet.appendChild(this.content);\n",
       "\n",
       "            this.title = document.createElement('div');\n",
       "            this.title.classList.add('facet-title');\n",
       "            const titleSpan = document.createElement('span');\n",
       "            titleSpan.appendChild(document.createTextNode(facetName));\n",
       "            this.title.appendChild(titleSpan);\n",
       "            this.facet.appendChild(this.title);\n",
       "        }\n",
       "\n",
       "        setData(data) {\n",
       "            this.nonFormatData = [];\n",
       "            this.heatIndexToNodeElement = []\n",
       "\n",
       "            while (this.content.childNodes.length > 0) {\n",
       "                this.content.removeChild(this.content.firstChild);\n",
       "            }\n",
       "\n",
       "            for (let i = 0; i < data.length; i++) {\n",
       "                const tokenNode = document.createElement('span');\n",
       "                const heatIndex = this.heatIndexToNodeElement.length;\n",
       "                tokenNode.appendChild(document.createTextNode(data[i].token));\n",
       "                if (this.settings.interactive && !data[i].format) {\n",
       "                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n",
       "                    this.heatIndexToNodeElement.push(tokenNode)\n",
       "                    this.nonFormatData.push(data[i])\n",
       "                }\n",
       "                this.content.appendChild(tokenNode);\n",
       "            }\n",
       "\n",
       "            if (this.highlightIndex !== null) {\n",
       "                this.highlight(this.highlightIndex);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        highlight(index) {\n",
       "            this.highlightIndex = index;\n",
       "\n",
       "            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n",
       "                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n",
       "                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n",
       "            }\n",
       "\n",
       "            if (this.settings.showMeta) {\n",
       "                while (this.meta.childNodes.length > 0) {\n",
       "                    this.meta.removeChild(this.meta.firstChild);\n",
       "                }\n",
       "\n",
       "                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n",
       "                    const item = document.createElement('div');\n",
       "                    item.classList.add('meta-content-item');\n",
       "                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n",
       "                    this.meta.appendChild(item);\n",
       "                }\n",
       "\n",
       "                if (this.nonFormatData[index].meta.length === 0) {\n",
       "                    const item = document.createElement('div');\n",
       "                    item.classList.add('meta-content-item');\n",
       "                    this.meta.appendChild(item);\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "\n",
       "    window.setupTextualHeatmap = function (settings) {\n",
       "        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n",
       "    };\n",
       "\n",
       "    window.setDataTextualHeatmap = function (settings, data) {\n",
       "        document.getElementById(settings.id).instance.setData(data);\n",
       "    };\n",
       "\n",
       "    window.highlightTextualHeatmap = function (settings, index) {\n",
       "        document.getElementById(settings.id).instance.highlight(index);\n",
       "    };\n",
       "})();</script><div id=\"a456573c-7275-42eb-b683-ba1a53f1b57b\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"a456573c-7275-42eb-b683-ba1a53f1b57b\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>  window.setDataTextualHeatmap({\"id\": \"a456573c-7275-42eb-b683-ba1a53f1b57b\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true}, [[{\"token\": \"\\u0c1a\\u0c3f\", \"meta\": [\"Core: h \", \"\\u0c3f: n \"], \"heat\": [1.0]}, {\"token\": \" \", \"format\": true}, {\"token\": \"\\u0c28\\u0c4d\", \"meta\": [\"Core: n n \", \"\\u0c4d: n d \"], \"heat\": [1.0]}, {\"token\": \" \", \"format\": true}, {\"token\": \"\\u0c28\", \"meta\": [\"Core: n n \"], \"heat\": [1.0]}, {\"token\": \" \", \"format\": true}, {\"token\": \"\\u0c21\\u0c3f\", \"meta\": [\"Core: d \", \"\\u0c3f: i \"], \"heat\": [1.0]}, {\"token\": \" \", \"format\": true}]]);</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>  window.highlightTextualHeatmap({\"id\": \"a456573c-7275-42eb-b683-ba1a53f1b57b\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Vis\"], \"rotateFacetTitles\": false, \"interactive\": true}, 159);</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # coding: utf-8\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# random_indexes = []\n",
    "# # outputs = []\n",
    "# # inputs = []\n",
    "# for i in range(9):\n",
    "#     a = np.random.randint(0,len(test_outputs))\n",
    "#     random_indexes.append(a)\n",
    "# fig = plt.figure(figsize = (15,15))\n",
    "# x = 1\n",
    "# for i in range(1):\n",
    "#     accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "#     # print(attention)\n",
    "#     attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "#     s = attention.shape\n",
    "#     attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "#     # plt.subplot(3,3,x)\n",
    "#     # print(attention.shape,attention)\n",
    "#     for a, b in z:\n",
    "#         decoded_word = a[1:-1]\n",
    "#         expected_word = b \n",
    "#     input_word = test_inputs[random_indexes[i]]\n",
    "#     print(len(input_word),input_word)\n",
    "#     print(len(decoded_word),decoded_word)\n",
    "#     attention = attention[:len(decoded_word),:len(input_word)]\n",
    "#     data = data_string2(attention,decoded_word,input_word)\n",
    "#     print(data)\n",
    "#     heatmap = TextualHeatmap(facet_titles = ['Vis'], show_meta=True)\n",
    "#     heatmap.set_data(data)\n",
    "#     heatmap.highlight(159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e8b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d420bcfd",
   "metadata": {},
   "source": [
    "# Wandb Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10baf71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mooizz (use `wandb login --relogin` to force relogin)\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Jaitesh/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login(key=\"866040d7d81f67025d43e7d50ecd83d54b6cf977\", relogin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "093bcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'val_word_accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "         'beam_size' : {\n",
    "            'values' : [1]\n",
    "        },\n",
    "        'input_embed_size': {\n",
    "            'values' : [16, 32, 64]\n",
    "        },\n",
    "        'hidden_size' : {\n",
    "            'values' : [128, 256, 512]\n",
    "        },\n",
    "        'cell_type' : {\n",
    "            'values' : ['GRU','LSTM','RNN']\n",
    "        },\n",
    "        'dropout' : {\n",
    "            'values' : [0, 0.2]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eab47e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ccz1whbm\n",
      "Sweep URL: https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"mooizz\",project=\"Rec_dakhashina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3bc7ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Model(input_embed_size , hidden_size, cell_type, dropout):\n",
    "    charinput = tf.keras.Input(shape=(None,),dtype='float32',name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars+1,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True )\n",
    "        encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    if cell_type == 'RNN':\n",
    "        encoder = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, return_state=True )\n",
    "        encoder_outputs, rnn_state = encoder(embedding)\n",
    "    if cell_type == 'GRU':\n",
    "        encoder = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True )\n",
    "        encoder_outputs, gru_state = encoder(embedding)\n",
    "        \n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1,64, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    if cell_type == 'RNN':\n",
    "        decoder_rnn = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _ = decoder_rnn(decoder_embedding, initial_state=rnn_state)\n",
    "    if cell_type == 'GRU':\n",
    "        decoder_gru = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=gru_state)\n",
    "    \n",
    "    # print(encoder_outputs.shape)\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    dense_time = tf.keras.layers.TimeDistributed(decoder_dense, name='time_distributed_layer')\n",
    "#     decoder_pred = dense_time(decoder_concat_input)\n",
    "    \n",
    "    decoder_outputs = dense_time(decoder_concat_input)\n",
    "    \n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    \n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder_states_attn = [encoder_outputs,state_h,state_c]\n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "        # define inference decoder\n",
    "    #     decoder_inf_out, decoder_inf_state = decoder_gru(decoder_inf_inputs, initial_state=decoder_init_state)\n",
    "    #     attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "    #     decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "    #     decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "    #     decoder_model = Model(inputs=[encoder_inf_states, decoder_init_state, decoder_inf_inputs],\n",
    "    #                           outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_state])\n",
    "\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "        attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "        decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "        decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "        decoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h,decoder_state_input_c]\n",
    "                                       , [decoder_outputs] + decoder_states + [attn_inf_states])\n",
    "    if cell_type == 'GRU':\n",
    "        encoder_states_attn = [encoder_outputs,gru_state]\n",
    "        \n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "        \n",
    "        decoder_outputs, state_h = decoder_gru(decoder_embedding, initial_state=decoder_state_input_h)\n",
    "        attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "        decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "        decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "#         decoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h]\n",
    "                                       , [decoder_outputs] + [state_h] + [attn_inf_states])\n",
    "    if cell_type == 'RNN':\n",
    "        encoder_states_attn = [encoder_outputs,rnn_state]\n",
    "        \n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states_attn)\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "#         decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "        encoder_inf_states = tf.keras.Input(shape=(None,hidden_size), name='encoder_inf_states')\n",
    "        \n",
    "        decoder_outputs, state_h = decoder_rnn(decoder_embedding, initial_state=decoder_state_input_h)\n",
    "        attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_outputs])\n",
    "        decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs, attn_inf_out])\n",
    "        decoder_outputs = tf.keras.layers.TimeDistributed(decoder_dense)(decoder_inf_concat)\n",
    "#         decoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [encoder_inf_states,decoder_state_input_h]\n",
    "                                       , [decoder_outputs] + [state_h] + [attn_inf_states])\n",
    "        \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52f0d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config_defaults = {\n",
    "        'epochs' : 20,\n",
    "        'batch_size' : 64,\n",
    "        'optimizer' : 'adam',\n",
    "        'beam_size' : 1,\n",
    "        'input_embed_size': 32,\n",
    "        'hidden_size' : 256,\n",
    "        'cell_type' : 'LSTM',\n",
    "        'dropout' : 0,\n",
    "    }\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    model, enc_model, dec_model = get_Model(config.input_embed_size,config.hidden_size,\n",
    "                     config.cell_type,\n",
    "                     config.dropout)\n",
    "    model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "#     sample_model.summary()\n",
    "    EarlyStopCB = tf.keras.callbacks.EarlyStopping(patience=30, monitor='val_accuracy',\n",
    "                                                  restore_best_weights=True)\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "    model.fit(\n",
    "        [input_tensor,decoder_input_data],\n",
    "        decoder_output_data,\n",
    "        batch_size=config.batch_size,\n",
    "        epochs=config.epochs,\n",
    "        validation_data=(\n",
    "            [val_input_tensor,decoder_val_input_data],\n",
    "            decoder_val_output_data\n",
    "        ),\n",
    "        shuffle=True,\n",
    "        callbacks=[WandbCallback(), EarlyStopCB])\n",
    "    beam_acc , _ , attention = beam_evaluate(val_input_tensor,valid_outputs,len(valid_outputs),config.beam_size,\n",
    "                                enc_model,\n",
    "                                dec_model,\n",
    "                                config.cell_type)\n",
    "    wandb.log({'val_word_accuracy' : beam_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e625837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 6o28he04 with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: GRU\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">exalted-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115436-6o28he04</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\exalted-sweep-1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\exalted-sweep-1\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 19120<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115436-6o28he04\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115436-6o28he04\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>79</td></tr><tr><td>_timestamp</td><td>1621319155</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">exalted-sweep-1</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/6o28he04</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: kbbhtcbm with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: LSTM\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sunny-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115626-kbbhtcbm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\sunny-sweep-2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\sunny-sweep-2\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17376<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115626-kbbhtcbm\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115626-kbbhtcbm\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>77</td></tr><tr><td>_timestamp</td><td>1621319263</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sunny-sweep-2</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/kbbhtcbm</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: asqtl5qt with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: RNN\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">leafy-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/ccz1whbm</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115817-asqtl5qt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaitesh\\.conda\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\leafy-sweep-3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\ccz1whbm\\leafy-sweep-3\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22420<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115817-asqtl5qt\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Jaitesh\\Desktop\\Courses\\DL\\RecurrentNetwork\\wandb\\run-20210518_115817-asqtl5qt\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>79</td></tr><tr><td>_timestamp</td><td>1621319376</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">leafy-sweep-3</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/asqtl5qt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "source": [
    "# Best Model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, enc_model, dec_model = get_Model(config.input_embed_size,config.hidden_size,\n",
    "                     config.cell_type,\n",
    "                     config.dropout)\n",
    "best_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopCB = tf.keras.callbacks.EarlyStopping(patience=30, monitor='val_accuracy',\n",
    "                                                  restore_best_weights=True)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "best_model.fit(\n",
    "        [input_tensor,decoder_input_data],\n",
    "        decoder_output_data,\n",
    "        batch_size=config.batch_size,\n",
    "        epochs=config.epochs,\n",
    "        validation_data=(\n",
    "            [val_input_tensor,decoder_val_input_data],\n",
    "            decoder_val_output_data\n",
    "        ),\n",
    "        shuffle=True,\n",
    "        callbacks=[WandbCallback(), EarlyStopCB]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1, attention = beam_evaluate(test_input_tensor,test_outputs,len(test_outputs),1,enc_model,dec_model,'LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "random_indexes = []\n",
    "# outputs = []\n",
    "# inputs = []\n",
    "for i in range(9):\n",
    "    a = np.random.randint(0,len(test_outputs))\n",
    "    random_indexes.append(a)\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "x = 1\n",
    "for i in range(9):\n",
    "    accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "    # print(attention)\n",
    "    attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "    s = attention.shape\n",
    "    attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "    plt.subplot(3,3,x)\n",
    "    # print(attention.shape,attention)\n",
    "    for a, b in z:\n",
    "        decoded_word = a[1:-1]\n",
    "        expected_word = b \n",
    "    input_word = test_inputs[random_indexes[i]]\n",
    "    print(len(input_word),input_word)\n",
    "    print(len(decoded_word),decoded_word)\n",
    "    attention = attention[:len(decoded_word),:len(input_word)]\n",
    "    print(attention)\n",
    "    plt.imshow(attention,cmap='gray')\n",
    "    font_prop = FontProperties(fname='Lohit-Telugu.ttf', size=18)\n",
    "   \n",
    "    # plt.xlim(len(input_word))\n",
    "    # plt.ylim(len(input_word))\n",
    "    labels = []\n",
    "    for s in decoded_word:\n",
    "        labels.append(s)\n",
    "\n",
    "    plt.yticks(range(len(labels)),labels,fontproperties = font_prop)\n",
    "    plt.xticks(range(len(input_word)),input_word)\n",
    "    x+=1\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "random_indexes = []\n",
    "# outputs = []\n",
    "# inputs = []\n",
    "for i in range(9):\n",
    "    a = np.random.randint(0,len(test_outputs))\n",
    "    random_indexes.append(a)\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "x = 1\n",
    "for i in range(1):\n",
    "    accruracy , z, attention = beam_evaluate_single(test_input_tensor,test_outputs,random_indexes[i],1,enc_model,dec_model,'LSTM')\n",
    "    # print(attention)\n",
    "    attention = np.asarray(np.asarray(attention)[:,0,:])\n",
    "    s = attention.shape\n",
    "    attention = attention.reshape(s[0],s[2])[:,:s[0]]\n",
    "    # plt.subplot(3,3,x)\n",
    "    # print(attention.shape,attention)\n",
    "    for a, b in z:\n",
    "        decoded_word = a[1:-1]\n",
    "        expected_word = b \n",
    "    input_word = test_inputs[random_indexes[i]]\n",
    "    print(len(input_word),input_word)\n",
    "    print(len(decoded_word),decoded_word)\n",
    "    attention = attention[:len(decoded_word),:len(input_word)]\n",
    "    data = data_string2(attention,decoded_word,input_word)\n",
    "    print(data)\n",
    "    heatmap = TextualHeatmap(facet_titles = ['Vis'], show_meta=True)\n",
    "    heatmap.set_data(data)\n",
    "    heatmap.highlight(159)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}