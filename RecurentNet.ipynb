{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3927e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5007e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58285d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getcwd() + os.sep + 'te' + os.sep + 'lexicons'\n",
    "train_path = dataset_path + os.sep + 'te.translit.sampled.train.tsv'\n",
    "valid_path = dataset_path + os.sep + 'te.translit.sampled.dev.tsv'\n",
    "test_path = dataset_path + os.sep + 'te.translit.sampled.test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6901b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "train_outputs = []\n",
    "valid_inputs = []\n",
    "valid_outputs = []\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "input_chars = set()\n",
    "output_chars = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad91d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748bb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "#     if not include_all and a!=1:\n",
    "#         continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    train_inputs.append(inp)\n",
    "    train_outputs.append(out)\n",
    "    for char in inp:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in out:\n",
    "        if char not in output_chars:\n",
    "            output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77599cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d3b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(valid_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    valid_inputs.append(inp)\n",
    "    valid_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56668b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    test_inputs.append(inp)\n",
    "    test_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e91aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "input_chars = sorted(list(input_chars))\n",
    "print(input_chars)\n",
    "num_input_chars = len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9618b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '\\u200c']\n"
     ]
    }
   ],
   "source": [
    "output_chars = sorted(list(output_chars))\n",
    "print(output_chars)\n",
    "num_output_chars = len(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacbd5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_inputs)\n",
    "max_input_size = max([len(txt) for txt in train_inputs])\n",
    "print(max_input_size)\n",
    "max_output_size = max([len(txt) for txt in  train_outputs])\n",
    "print(max_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a8b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "output_index = dict([(char, i+1) for i, char in enumerate(output_chars)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba93c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 1, '\\n': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
     ]
    }
   ],
   "source": [
    "print(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8f0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Enoding in indexes of characters in the set\n",
    "def encode_index(inputs,index):\n",
    "    data = []\n",
    "    for i in range(len(inputs)):\n",
    "        a = np.zeros(len(inputs[i]))\n",
    "        j = 0\n",
    "        for char in inputs[i]:\n",
    "            a[j] = index[char]\n",
    "            j += 1\n",
    "        data.append(a)\n",
    "    data = np.asarray(data).astype(np.ndarray)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d8d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = []\n",
    "# for i in range(train_size):\n",
    "#     a = np.zeros(len(train_inputs[i]))\n",
    "#     j = 0\n",
    "#     for char in train_inputs[i]:\n",
    "#         a[j] = input_index[char]\n",
    "#         j += 1\n",
    "#     input_data.append(a)\n",
    "# input_data = np.asarray(input_data).astype(np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093d2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "input_data = encode_index(train_inputs,input_index)\n",
    "input_tensor = tf.ragged.constant(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe035ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_data = encode_index(valid_inputs,input_index)\n",
    "val_input_tensor = tf.ragged.constant(val_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e45a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data = encode_index(test_inputs,input_index)\n",
    "test_input_tensor = tf.ragged.constant(test_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953483ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58550\n"
     ]
    }
   ],
   "source": [
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "350640cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val__input_size = max([len(txt) for txt in valid_inputs])\n",
    "max_val_output_size = max([len(txt) for txt in  valid_outputs])\n",
    "max_test_input_size = max([len(txt) for txt in test_inputs])\n",
    "max_test_output_size = max([len(txt) for txt in  test_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b26ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_output_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(train_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "# print(decoder_input_data[0])\n",
    "decoder_input_data = np.argmax(decoder_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_output_data = np.argmax(decoder_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_input_data = tf.convert_to_tensor(decoder_input_data)\n",
    "# decoder_output_data = tf.convert_to_tensor(decoder_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8681f530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  5.,  3., 18., 53., 32.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d32549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_val_input_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_val_output_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(valid_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_val_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_val_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_val_input_data = np.argmax(decoder_val_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_output_data = np.argmax(decoder_val_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_input_data = tf.convert_to_tensor(decoder_val_input_data)\n",
    "# decoder_val_output_data = tf.convert_to_tensor(decoder_val_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52f20581",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_test_input_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_test_output_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(test_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_test_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_test_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_test_input_data = np.argmax(decoder_test_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_output_data = np.argmax(decoder_test_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_input_data = tf.convert_to_tensor(decoder_test_input_data)\n",
    "# decoder_test_output_data = tf.convert_to_tensor(decoder_test_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "# embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13b5339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(charinput,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b7e8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\"rmsprop\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "745cffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model.predict(input_data[0])\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb688c59",
   "metadata": {},
   "source": [
    "# Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b62a425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_model(input_embed_size , hidden_size):\n",
    "    charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    encoder = tf.keras.layers.LSTM(hidden_size, return_state=True )\n",
    "    encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1,64, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    \n",
    "    encoder_model = tf.keras.Model(charinput, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d476dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model, enc_model, dec_model = get_sample_model(32,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c71b19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 32)     832         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 64)     4224        decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 295936      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  328704      decoder_embedding[0][0]          \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 66)     16962       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 646,658\n",
      "Trainable params: 646,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "sample_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cc12abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_output_chars+1))\n",
    "    target_seq[0, 0, output_index[\"\\t\"]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = dec_model.predict([target_seq] + states_value)\n",
    "\n",
    "#         print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "#         print(sampled_token_index)\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "#         print(sampled_char)\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or sampled_char == ' ' or len(decoded_sentence) > max_output_size:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_output_chars+1))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60cea938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: amkita\n",
      "Decoded sentence: అంకిత\n",
      "\n",
      "-\n",
      "Input sentence: ankita\n",
      "Decoded sentence: అంకిత\n",
      "\n",
      "-\n",
      "Input sentence: ankitha\n",
      "Decoded sentence: అంకిత\n",
      "\n",
      "-\n",
      "Input sentence: ankitam\n",
      "Decoded sentence: అంకితం\n",
      "\n",
      "-\n",
      "Input sentence: ankitham\n",
      "Decoded sentence: అంకితం\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seqid in range(5):\n",
    "    input_seq = input_tensor[seqid:seqid+1]\n",
    "#     print(input_seq.shape,input_tensor.shape)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", train_inputs[seqid])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "962dfe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83f42ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "915/915 [==============================] - 557s 608ms/step - loss: 1.1125 - accuracy: 0.2398 - val_loss: 0.6072 - val_accuracy: 0.5180\n",
      "Epoch 2/10\n",
      "915/915 [==============================] - 583s 637ms/step - loss: 0.5154 - accuracy: 0.5823 - val_loss: 0.3018 - val_accuracy: 0.7017\n",
      "Epoch 3/10\n",
      "915/915 [==============================] - 583s 637ms/step - loss: 0.2661 - accuracy: 0.7337 - val_loss: 0.2127 - val_accuracy: 0.7572\n",
      "Epoch 4/10\n",
      "915/915 [==============================] - 594s 649ms/step - loss: 0.1821 - accuracy: 0.7858 - val_loss: 0.1810 - val_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "915/915 [==============================] - 590s 645ms/step - loss: 0.1412 - accuracy: 0.8114 - val_loss: 0.1604 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "915/915 [==============================] - 658s 719ms/step - loss: 0.1154 - accuracy: 0.8284 - val_loss: 0.1554 - val_accuracy: 0.7923\n",
      "Epoch 7/10\n",
      "915/915 [==============================] - 651s 711ms/step - loss: 0.0985 - accuracy: 0.8388 - val_loss: 0.1453 - val_accuracy: 0.7992\n",
      "Epoch 8/10\n",
      "915/915 [==============================] - 659s 719ms/step - loss: 0.0830 - accuracy: 0.8483 - val_loss: 0.1447 - val_accuracy: 0.7985\n",
      "Epoch 9/10\n",
      "915/915 [==============================] - 641s 699ms/step - loss: 0.0724 - accuracy: 0.8553 - val_loss: 0.1436 - val_accuracy: 0.8015\n",
      "Epoch 10/10\n",
      "915/915 [==============================] - 654s 714ms/step - loss: 0.0636 - accuracy: 0.8607 - val_loss: 0.1418 - val_accuracy: 0.8018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22982efae48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model.fit(\n",
    "    [input_tensor,decoder_input_data],\n",
    "    decoder_output_data,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_data=([val_input_tensor,decoder_val_input_data],decoder_val_output_data),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b5d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_tensor,data_output,k):\n",
    "    crct = 0\n",
    "    for seqid in range(k):\n",
    "        input_seq = data_tensor[seqid:seqid+1]\n",
    "#     print(input_seq.shape,input_tensor.shape)\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        st = data_output[seqid][1:]\n",
    "        if(st!=decoded_sentence):\n",
    "            pass\n",
    "        else:\n",
    "            crct+=1\n",
    "    return crct/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42d57cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44892987645728205\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(test_input_tensor,test_outputs,len(test_input_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cfeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10baf71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093bcd65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab47e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7ce33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
