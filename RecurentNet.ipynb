{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3927e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5007e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# %config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58285d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getcwd() + os.sep + 'te' + os.sep + 'lexicons'\n",
    "train_path = dataset_path + os.sep + 'te.translit.sampled.train.tsv'\n",
    "valid_path = dataset_path + os.sep + 'te.translit.sampled.dev.tsv'\n",
    "test_path = dataset_path + os.sep + 'te.translit.sampled.test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6901b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = []\n",
    "train_outputs = []\n",
    "valid_inputs = []\n",
    "valid_outputs = []\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "input_chars = set()\n",
    "output_chars = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad91d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748bb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "#     if not include_all and a!=1:\n",
    "#         continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    train_inputs.append(inp)\n",
    "    train_outputs.append(out)\n",
    "    for char in inp:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in out:\n",
    "        if char not in output_chars:\n",
    "            output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77599cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d3b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(valid_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    valid_inputs.append(inp)\n",
    "    valid_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56668b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: (len(lines) - 1 )]:\n",
    "    out,inp,a = line.split('\\t')\n",
    "    if not include_all and a!=1:\n",
    "        continue\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     print(out,out[-1],inp,inp[-1])\n",
    "    out = \"\\t\" + out + \"\\n\"\n",
    "    test_inputs.append(inp)\n",
    "    test_outputs.append(out)\n",
    "#     for char in inp:\n",
    "#         if char not in input_chars:\n",
    "#             input_chars.add(char)\n",
    "#     for char in out:\n",
    "#         if char not in output_chars:\n",
    "#             output_chars.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e91aed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "input_chars = sorted(list(input_chars))\n",
    "print(input_chars)\n",
    "num_input_chars = len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9618b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్', '\\u200c']\n"
     ]
    }
   ],
   "source": [
    "output_chars = sorted(list(output_chars))\n",
    "print(output_chars)\n",
    "num_output_chars = len(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aacbd5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_inputs)\n",
    "max_input_size = max([len(txt) for txt in train_inputs])\n",
    "print(max_input_size)\n",
    "max_output_size = max([len(txt) for txt in  train_outputs])\n",
    "print(max_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a8b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "output_index = dict([(char, i+1) for i, char in enumerate(output_chars)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba93c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 1, '\\n': 2, 'ం': 3, 'ః': 4, 'అ': 5, 'ఆ': 6, 'ఇ': 7, 'ఈ': 8, 'ఉ': 9, 'ఊ': 10, 'ఋ': 11, 'ఎ': 12, 'ఏ': 13, 'ఐ': 14, 'ఒ': 15, 'ఓ': 16, 'ఔ': 17, 'క': 18, 'ఖ': 19, 'గ': 20, 'ఘ': 21, 'చ': 22, 'ఛ': 23, 'జ': 24, 'ఝ': 25, 'ఞ': 26, 'ట': 27, 'ఠ': 28, 'డ': 29, 'ఢ': 30, 'ణ': 31, 'త': 32, 'థ': 33, 'ద': 34, 'ధ': 35, 'న': 36, 'ప': 37, 'ఫ': 38, 'బ': 39, 'భ': 40, 'మ': 41, 'య': 42, 'ర': 43, 'ఱ': 44, 'ల': 45, 'ళ': 46, 'వ': 47, 'శ': 48, 'ష': 49, 'స': 50, 'హ': 51, 'ా': 52, 'ి': 53, 'ీ': 54, 'ు': 55, 'ూ': 56, 'ృ': 57, 'ె': 58, 'ే': 59, 'ై': 60, 'ొ': 61, 'ో': 62, 'ౌ': 63, '్': 64, '\\u200c': 65}\n"
     ]
    }
   ],
   "source": [
    "print(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8f0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Enoding in indexes of characters in the set\n",
    "def encode_index(inputs,index):\n",
    "    data = []\n",
    "    for i in range(len(inputs)):\n",
    "        a = np.zeros(len(inputs[i]))\n",
    "        j = 0\n",
    "        for char in inputs[i]:\n",
    "            a[j] = index[char]\n",
    "            j += 1\n",
    "        data.append(a)\n",
    "    data = np.asarray(data).astype(np.ndarray)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d8d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = []\n",
    "# for i in range(train_size):\n",
    "#     a = np.zeros(len(train_inputs[i]))\n",
    "#     j = 0\n",
    "#     for char in train_inputs[i]:\n",
    "#         a[j] = input_index[char]\n",
    "#         j += 1\n",
    "#     input_data.append(a)\n",
    "# input_data = np.asarray(input_data).astype(np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093d2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "input_data = encode_index(train_inputs,input_index)\n",
    "input_tensor = tf.ragged.constant(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe035ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_data = encode_index(valid_inputs,input_index)\n",
    "val_input_tensor = tf.ragged.constant(val_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e45a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_data = encode_index(test_inputs,input_index)\n",
    "test_input_tensor = tf.ragged.constant(test_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953483ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58550\n"
     ]
    }
   ],
   "source": [
    "print(len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "350640cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val__input_size = max([len(txt) for txt in valid_inputs])\n",
    "max_val_output_size = max([len(txt) for txt in  valid_outputs])\n",
    "max_test_input_size = max([len(txt) for txt in test_inputs])\n",
    "max_test_output_size = max([len(txt) for txt in  test_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b26ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_output_data = np.zeros(\n",
    "    (len(train_inputs), max_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(train_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "# print(decoder_input_data[0])\n",
    "decoder_input_data = np.argmax(decoder_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_output_data = np.argmax(decoder_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_input_data = tf.convert_to_tensor(decoder_input_data)\n",
    "# decoder_output_data = tf.convert_to_tensor(decoder_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8681f530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  5.,  3., 18., 53., 32.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d32549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_val_input_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_val_output_data = np.zeros(\n",
    "    (len(valid_inputs), max_val_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(valid_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_val_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_val_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_val_input_data = np.argmax(decoder_val_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_output_data = np.argmax(decoder_val_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_val_input_data = tf.convert_to_tensor(decoder_val_input_data)\n",
    "# decoder_val_output_data = tf.convert_to_tensor(decoder_val_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52f20581",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_test_input_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "decoder_test_output_data = np.zeros(\n",
    "    (len(test_inputs), max_test_output_size,num_output_chars+1), dtype=\"float32\"\n",
    ")\n",
    "for i,target_text in enumerate(test_outputs):\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_test_input_data[i, t, output_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_test_output_data[i, t - 1, output_index[char]] = 1.0\n",
    "#     decoder_input_data[i, t + 1 :, output_index[\" \"]] = 1.0\n",
    "#     decoder_output_data[i, t:, output_index[\" \"]] = 1.0\n",
    "decoder_test_input_data = np.argmax(decoder_test_input_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_output_data = np.argmax(decoder_test_output_data,axis=2).astype(dtype='float32')\n",
    "# decoder_test_input_data = tf.convert_to_tensor(decoder_test_input_data)\n",
    "# decoder_test_output_data = tf.convert_to_tensor(decoder_test_output_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50801eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "# embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13b5339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(charinput,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b7e8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\"rmsprop\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "745cffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model.predict(input_data[0])\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb688c59",
   "metadata": {},
   "source": [
    "# Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b62a425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_model(input_embed_size , hidden_size):\n",
    "    charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    encoder = tf.keras.layers.LSTM(hidden_size, return_state=True )\n",
    "    encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1,64, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    \n",
    "    encoder_model = tf.keras.Model(charinput, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d476dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model, enc_model, dec_model = get_sample_model(32,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c71b19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 32)     832         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 64)     4224        decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 295936      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  328704      decoder_embedding[0][0]          \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 66)     16962       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 646,658\n",
      "Trainable params: 646,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "sample_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6cc12abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def decode_single_sequence(input_seq):\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_output_chars+1))\n",
    "    target_seq[0, 0, output_index[\"\\t\"]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = dec_model.predict([target_seq] + states_value)\n",
    "\n",
    "#         print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "#         print(sampled_token_index)\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "#         print(sampled_char)\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or sampled_char == ' ' or len(decoded_sentence) > max_output_size:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_output_chars+1))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence\n",
    "def decode_sequence(input_seq):\n",
    "    sz  = input_seq.shape[0]\n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    target_seq = np.zeros((sz,1,num_output_chars+1))\n",
    "    for i in range(sz):\n",
    "        target_seq[i, 0, output_index[\"\\t\"]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    decoded_seqs = [\"\" for i in range(sz)]\n",
    "    j = 0\n",
    "    while j < max_output_size:\n",
    "        output_tokens, h, c = dec_model.predict([target_seq] + states_value)\n",
    "\n",
    "#         print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "        target_seq = np.zeros((sz, 1, num_output_chars+1))\n",
    "        for i in range(sz):\n",
    "            sampled_char = reverse_target_char_index[sampled_token_index[i]]\n",
    "            decoded_seqs[i] += sampled_char\n",
    "            target_seq[i, 0, sampled_token_index[i]] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        # Update states\n",
    "        states_value = [h,c]\n",
    "        j+=1\n",
    "    output = [ (\"\\t\"+st.split('\\n')[0]+\"\\n\") for st in decoded_seqs]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "60cea938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: amkita\n",
      "Decoded sentence: అంకిత\n",
      "\n",
      "-\n",
      "Input sentence: ankita\n",
      "Decoded sentence: అంకిత\n",
      "\n",
      "-\n",
      "Input sentence: ankitha\n",
      "Decoded sentence: అంకిత\n",
      "\n",
      "-\n",
      "Input sentence: ankitam\n",
      "Decoded sentence: అంకితం\n",
      "\n",
      "-\n",
      "Input sentence: ankitham\n",
      "Decoded sentence: అంకితం\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seqid in range(5):\n",
    "    input_seq = input_tensor[seqid:seqid+1]\n",
    "#     print(input_seq.shape,input_tensor.shape)\n",
    "    decoded_sentence = decode_single_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", train_inputs[seqid])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "962dfe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83f42ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "915/915 [==============================] - 557s 608ms/step - loss: 1.1125 - accuracy: 0.2398 - val_loss: 0.6072 - val_accuracy: 0.5180\n",
      "Epoch 2/10\n",
      "915/915 [==============================] - 583s 637ms/step - loss: 0.5154 - accuracy: 0.5823 - val_loss: 0.3018 - val_accuracy: 0.7017\n",
      "Epoch 3/10\n",
      "915/915 [==============================] - 583s 637ms/step - loss: 0.2661 - accuracy: 0.7337 - val_loss: 0.2127 - val_accuracy: 0.7572\n",
      "Epoch 4/10\n",
      "915/915 [==============================] - 594s 649ms/step - loss: 0.1821 - accuracy: 0.7858 - val_loss: 0.1810 - val_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "915/915 [==============================] - 590s 645ms/step - loss: 0.1412 - accuracy: 0.8114 - val_loss: 0.1604 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "915/915 [==============================] - 658s 719ms/step - loss: 0.1154 - accuracy: 0.8284 - val_loss: 0.1554 - val_accuracy: 0.7923\n",
      "Epoch 7/10\n",
      "915/915 [==============================] - 651s 711ms/step - loss: 0.0985 - accuracy: 0.8388 - val_loss: 0.1453 - val_accuracy: 0.7992\n",
      "Epoch 8/10\n",
      "915/915 [==============================] - 659s 719ms/step - loss: 0.0830 - accuracy: 0.8483 - val_loss: 0.1447 - val_accuracy: 0.7985\n",
      "Epoch 9/10\n",
      "915/915 [==============================] - 641s 699ms/step - loss: 0.0724 - accuracy: 0.8553 - val_loss: 0.1436 - val_accuracy: 0.8015\n",
      "Epoch 10/10\n",
      "915/915 [==============================] - 654s 714ms/step - loss: 0.0636 - accuracy: 0.8607 - val_loss: 0.1418 - val_accuracy: 0.8018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22982efae48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model.fit(\n",
    "    [input_tensor,decoder_input_data],\n",
    "    decoder_output_data,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_data=([val_input_tensor,decoder_val_input_data],decoder_val_output_data),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7b5d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_tensor,data_output,k):\n",
    "    crct = 0\n",
    "    input_seq = data_tensor[:k]\n",
    "#     print(input_seq.shape,input_tensor.shape)\n",
    "    decoded_sentences = decode_sequence(input_seq)\n",
    "    sts = data_output[:k]\n",
    "    crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "#         print(crct/(seqid+1))\n",
    "#         for st,d in zip(sts,decoded_sentences):\n",
    "#             print(st+\"_o\")\n",
    "#             print(d+\"_o\")\n",
    "    return crct/k,zip(decoded_sentences,sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42d57cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = evaluate(test_input_tensor,test_outputs,len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba4dc18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44892987645728205\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4762d",
   "metadata": {},
   "source": [
    "# Beam Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "c339ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 0.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score - log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select k best\n",
    "        sequences = ordered[:k]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "8d06a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def beam_search(outputs, k, output_words, reverse_index):\n",
    "#     for i in range(len(outputs)):\n",
    "#         seqs = beam_search_decoder(outputs[i],k)\n",
    "import math\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_index.items())\n",
    "reverse_target_char_index[0] = ' '\n",
    "\n",
    "def beam_decode(input_seq, beam_size, enc_model, dec_model, cell_type):\n",
    "    sz  = input_seq.shape[0]\n",
    "    \n",
    "    states_value = enc_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((sz,1,num_output_chars+1))\n",
    "    \n",
    "    for i in range(sz):\n",
    "        target_seq[i, 0, output_index[\"\\t\"]] = 1.0\n",
    "    \n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "    print(\"check1\")\n",
    "    decoded_seqs = [\"\" for i in range(sz)]\n",
    "    if cell_type == 'LSTM':\n",
    "        output_tokens, h, c = dec_model.predict([target_seq] + states_value)\n",
    "        states = [h,c]\n",
    "    if cell_type == 'GRU' or cell_type == 'RNN':\n",
    "        output_tokens, h = dec_model.predict([target_seq] + [states_value])\n",
    "        states = [h]\n",
    "    \n",
    "    print(\"check2\")\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(sz):\n",
    "        sequences.append([])\n",
    "#     beam_decoded \n",
    "    sampled_token_beam = np.argpartition(output_tokens[:, -1, :], -beam_size ,axis=1)[:,-beam_size:]\n",
    "    sampled_token_indexes = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "#     print(sampled_token_beam.shape,sampled_token_indexes.shape)\n",
    "    for i in range(sz):\n",
    "        allcandidates = list()\n",
    "        for j in range(beam_size):\n",
    "            allcandidates.append(\n",
    "                    [ [ sampled_token_beam[i][j] ],\n",
    "                        -np.log( \n",
    "                        output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                        states ,\n",
    "                        False])\n",
    "        ordered = sorted(allcandidates, key=lambda tup:tup[1])\n",
    "        sequences[i] = ordered[:beam_size]\n",
    "        \n",
    "    \n",
    "    \n",
    "    print(\"check3\")\n",
    "    target_seq = np.zeros((sz, beam_size, num_output_chars+1))\n",
    "#     states_beam = []\n",
    "    for i in range(sz):\n",
    "        for j in range(beam_size): \n",
    "#             sampled_char = reverse_target_char_index[sequences[i][j][0][-1]]\n",
    "#             decoded_seqs[i]\n",
    "#             print(j,sequences[i][j][0][-1]\n",
    "            target_seq[i, j, sequences[i][j][0][-1]] = 1.0\n",
    "    target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "#     enc_out = states_value[0]\n",
    "    \n",
    "#     for i in range(beam_size):\n",
    "#         a = []\n",
    "# #         a.append(enc_out)\n",
    "#         a.append(h)\n",
    "#         a.append(c)\n",
    "#         states_beam.append(a)\n",
    "#     states_value[1] = h\n",
    "#     states_value[2] = c\n",
    "#     a = []\n",
    "#     for j in range(beam_size):\n",
    "#         st = \"\"\n",
    "#         for ind in sequences[0][j][0]:\n",
    "#             st += reverse_target_char_index[ind]\n",
    "#         a.append( (\"\\t\"+st+\"\\n\",sequences[0][j][1]) )\n",
    "#     print(a)\n",
    "#     print()\n",
    "    it = 1\n",
    "    while it < max_output_size:\n",
    "        allcandidates = [list() for i in range(sz)]\n",
    "        for k in range(len(sequences[i])):\n",
    "#             print(target_seq.shape)\n",
    "#             print(target_seq[:,k],sequences[i][k][2])\n",
    "            if cell_type == 'LSTM':\n",
    "                output_tokens, h, c = dec_model.predict(\n",
    "                [target_seq[:,k]] + \n",
    "                sequences[i][k][2])\n",
    "                states = [h,c]\n",
    "            if cell_type == 'GRU' or cell_type == 'RNN':\n",
    "                output_tokens, h = dec_model.predict(\n",
    "                [target_seq[:,k]] + \n",
    "                sequences[i][k][2])\n",
    "                states = [h]\n",
    "            sampled_token_beam = np.argpartition(output_tokens[:, -1, :], -beam_size ,axis=1)[:,-beam_size:]\n",
    "            sampled_token_indexes = np.argmax(output_tokens[:, -1, :],axis=1)\n",
    "            \n",
    "#             print(output_tokens)\n",
    "#             print(sampled_token_beam.shape,sampled_token_indexes.shape)\n",
    "            for i in range(sz):\n",
    "                    if sequences[i][k][3]:\n",
    "                        allcandidates[i].append(\n",
    "                                [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                                 sequences[i][k][1],\n",
    "                                           states, True ])\n",
    "                        continue\n",
    "                    for j in range(beam_size):\n",
    "                        if reverse_target_char_index[sampled_token_beam[i][j]]=='\\n':\n",
    "                            allcandidates[i].append(\n",
    "                                [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                                 sequences[i][k][1]-np.log( \n",
    "                                     output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                                           states, True ])\n",
    "                        else:\n",
    "                            allcandidates[i].append(\n",
    "                            [ sequences[i][k][0]+[ sampled_token_beam[i][j] ],\n",
    "                             sequences[i][k][1]-np.log( \n",
    "                                 output_tokens[i][-1][sampled_token_beam[i][j]]),\n",
    "                                       states, False ])\n",
    "        for i in range(sz):\n",
    "            ordered = sorted(allcandidates[i], key=lambda tup:tup[1])\n",
    "            sequences[i] = ordered[:beam_size]\n",
    "#         for i in range(sz):\n",
    "#             print(\"all\")\n",
    "#             a = []\n",
    "#             for j in range(len(allcandidates[i])):\n",
    "#                 st = \"\"\n",
    "#                 for ind in allcandidates[i][j][0]:\n",
    "#                     st += reverse_target_char_index[ind]\n",
    "#                 a.append( (\"\\t\"+st+\"\\n\",allcandidates[i][j][1]) )\n",
    "#             print(a)\n",
    "#             print()\n",
    "#             print(\"seq\")\n",
    "#             a = []\n",
    "#             for j in range(beam_size):\n",
    "#                 st = \"\"\n",
    "#                 for ind in sequences[i][j][0]:\n",
    "#                     st += reverse_target_char_index[ind]\n",
    "#                 a.append( (\"\\t\"+st+\"\\n\",sequences[i][j][1]) )\n",
    "#             print(a)\n",
    "#             print()\n",
    "        target_seq = np.zeros((sz, beam_size, num_output_chars+1))\n",
    "        for i in range(sz):\n",
    "            for j in range(beam_size): \n",
    "                target_seq[i, j, sequences[i][j][0][-1]] = 1.0\n",
    "        target_seq = np.argmax(target_seq,axis=2).astype('float32')\n",
    "        it+=1\n",
    "#     output = [ (\"\\t\"+st.split('\\n')[0]+\"\\n\") for st in decoded_seqs]\n",
    "    output = []\n",
    "    for i in range(sz):\n",
    "        st = \"\"\n",
    "        for ind in sequences[i][0][0]:\n",
    "            st += reverse_target_char_index[ind]\n",
    "        output.append(\"\\t\"+st.split('\\n')[0]+\"\\n\")\n",
    "            \n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "6bd34f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_seq = test_input_tensor[:100]\n",
    "#     print(input_seq.shape,input_tensor.shape\n",
    "# beam_decode(input_seq,1)\n",
    "def beam_evaluate(data_tensor,data_output,k,beam_size,enc_model, dec_model, cell_type):\n",
    "    crct = 0\n",
    "    input_seq = data_tensor[:k]\n",
    "    decoded_sentences = beam_decode(input_seq,beam_size,enc_model, dec_model, cell_type)\n",
    "    sts = data_output[:k]\n",
    "    crct += np.sum(np.array(sts) == np.array(decoded_sentences))\n",
    "    return crct/k,zip(decoded_sentences,sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "028b6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1 = beam_evaluate(test_input_tensor,test_outputs,100,1,enc_model,dec_model,'LSTM')\n",
    "\n",
    "a2, b2 = evaluate(test_input_tensor,test_outputs,100)\n",
    "# print(a1,a2)\n",
    "# for ((l,m),(n,o)) in zip(b1,b2):\n",
    "#     print(l,m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "22a6f6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57 0.57\n"
     ]
    }
   ],
   "source": [
    "print(a1,a2)\n",
    "# # for c,d in b:\n",
    "# #     print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "27ce1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = beam_evaluate(test_input_tensor,test_outputs,100,5,enc_model,dec_model,cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ba3403a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "# for c,d in b:\n",
    "#     print(c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38febd90",
   "metadata": {},
   "source": [
    "# Wandb Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "10baf71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mooizz (use `wandb login --relogin` to force relogin)\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publically.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\HP/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login(key=\"866040d7d81f67025d43e7d50ecd83d54b6cf977\", relogin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "093bcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'val_accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "         'beam_size' : {\n",
    "            'values' : [1]\n",
    "        },\n",
    "        'input_embed_size': {\n",
    "            'values' : [32, 64]\n",
    "        },\n",
    "        'hidden_size' : {\n",
    "            'values' : [64]\n",
    "        },\n",
    "        'cell_type' : {\n",
    "            'values' : ['GRU','LSTM','RNN']\n",
    "        },\n",
    "        'num_decoder_layers' : {\n",
    "            'values' : [1]\n",
    "        },\n",
    "        'num_encoder_layers' : {\n",
    "            'values' : [1]\n",
    "        },\n",
    "        'dropout' : {\n",
    "            'values' : [0]\n",
    "        },\n",
    "       \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "eab47e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: h9nur1ze\n",
      "Sweep URL: https://wandb.ai/mooizz/Rec_dakhashina/sweeps/h9nur1ze\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"mooizz\",project=\"Rec_dakhashina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "3bc7ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Model(input_embed_size, hidden_size, cell_type, num_decoder_layers, num_encoder_layers, dropout, decoder_embed_size = 64):\n",
    "    charinput = tf.keras.Input(shape=(None,),name=\"input\")\n",
    "    embedding = tf.keras.layers.Embedding(num_input_chars,input_embed_size, name=\"embedding\")(charinput)\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder = tf.keras.layers.LSTM(hidden_size, return_sequences=True,\n",
    "                                       return_state=True, dropout=dropout,recurrent_dropout=dropout )\n",
    "        encoder_outputs, state_h, state_c = encoder(embedding)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    if cell_type == 'RNN':\n",
    "        encoder = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True,\n",
    "                                            return_state=True, dropout=dropout,recurrent_dropout=dropout )\n",
    "        encoder_outputs, rnn_state = encoder(embedding)\n",
    "    if cell_type == 'GRU':\n",
    "        encoder = tf.keras.layers.GRU(hidden_size, return_sequences=True,\n",
    "                                      return_state=True, dropout=dropout,recurrent_dropout=dropout )\n",
    "        encoder_outputs, gru_state = encoder(embedding)\n",
    "    \n",
    "        \n",
    "    \n",
    "    decoder_inputs = tf.keras.Input(shape=(None,),name=\"decoder_input\")\n",
    "    decoder_embedding = tf.keras.layers.Embedding(num_output_chars + 1, decoder_embed_size, name=\"decoder_embedding\",mask_zero=True)(decoder_inputs)\n",
    "    \n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True,\n",
    "                                            return_state=True, dropout=dropout,recurrent_dropout=dropout)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    if cell_type == 'RNN':\n",
    "        decoder_rnn = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True,\n",
    "                                                return_state=True, dropout=dropout,recurrent_dropout=dropout)\n",
    "        decoder_outputs, _ = decoder_rnn(decoder_embedding, initial_state=rnn_state)\n",
    "    if cell_type == 'GRU':\n",
    "        decoder_gru = tf.keras.layers.GRU(hidden_size, return_sequences=True,\n",
    "                                          return_state=True, dropout=dropout,recurrent_dropout=dropout)\n",
    "        decoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=gru_state)\n",
    "    \n",
    "    decoder_dense = tf.keras.layers.Dense(num_output_chars + 1, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = tf.keras.Model([charinput,decoder_inputs],decoder_outputs)\n",
    "    if cell_type == 'LSTM':\n",
    "        encoder_model = tf.keras.Model(charinput, encoder_states)\n",
    "        # define inference decoder\n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_state_input_c = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    if cell_type == 'GRU':\n",
    "        encoder_model = tf.keras.Model(charinput, gru_state)\n",
    "        \n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_outputs, state_h = decoder_gru(decoder_embedding, initial_state=decoder_state_input_h)\n",
    "    \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [decoder_state_input_h], [decoder_outputs] + [state_h])\n",
    "    if cell_type == 'RNN':\n",
    "        encoder_model = tf.keras.Model(charinput, rnn_state)\n",
    "        \n",
    "        decoder_state_input_h = tf.keras.Input(shape=(hidden_size,))\n",
    "        decoder_outputs, state_h = decoder_rnn(decoder_embedding, initial_state=decoder_state_input_h)\n",
    "    \n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = tf.keras.Model([decoder_inputs] + [decoder_state_input_h], [decoder_outputs] + [state_h])\n",
    "        \n",
    "        \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48035232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "46ff61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    config_defaults = {\n",
    "        'epochs' : 1,\n",
    "        'batch_size' : 64,\n",
    "        'optimizer' : 'adam',\n",
    "        'beam_size' : 1,\n",
    "        'input_embed_size': 32,\n",
    "        'hidden_size' : 256,\n",
    "        'cell_type' : 'LSTM',\n",
    "        'num_decoder_layers' : 1,\n",
    "        'num_encoder_layers' : 1,\n",
    "        'dropout' : 0,\n",
    "    }\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    model, enc_model, dec_model = get_Model(config.input_embed_size,config.hidden_size,\n",
    "                     config.cell_type,\n",
    "                     config.num_decoder_layers,\n",
    "                     config.num_encoder_layers,\n",
    "                     config.dropout)\n",
    "    model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "#     sample_model.summary()\n",
    "    EarlyStopCB = tf.keras.callbacks.EarlyStopping(patience=30, monitor='val_accuracy',\n",
    "                                                  restore_best_weights=True)\n",
    "    tf.config.run_functions_eagerly(True)\n",
    "#     model.fit(\n",
    "#         [input_tensor,decoder_input_data],\n",
    "#         decoder_output_data,\n",
    "#         batch_size=config.batch_size,\n",
    "#         epochs=config.epochs,\n",
    "#         validation_data=(\n",
    "#             [val_input_tensor,decoder_val_input_data],\n",
    "#             decoder_val_output_data\n",
    "#         ),\n",
    "#         shuffle=True,\n",
    "#         callbacks=[WandbCallback(), EarlyStopCB])\n",
    "    beam_acc , _ = beam_evaluate(val_input_tensor,valid_outputs,len(valid_outputs),config.beam_size,\n",
    "                                enc_model,\n",
    "                                dec_model,\n",
    "                                config.cell_type)\n",
    "    print(\"Testing\")\n",
    "    wandb.log({'Val_word_Acc' : beam_acc})\n",
    "    model.save('models'+os.sep+str(sweep_id)+os.sep+wandb.run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "9aab0ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: qm283mxc with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: GRU\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 32\n",
      "wandb: \tnum_decoder_layers: 1\n",
      "wandb: \tnum_encoder_layers: 1\n",
      "wandb: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">blooming-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/h9nur1ze\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/h9nur1ze</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/qm283mxc\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/qm283mxc</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210508_212017-qm283mxc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check2\n",
      "check3\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\h9nur1ze\\blooming-sweep-1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\h9nur1ze\\blooming-sweep-1\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26496<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210508_212017-qm283mxc\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210508_212017-qm283mxc\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>67</td></tr><tr><td>_timestamp</td><td>1620489084</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">blooming-sweep-1</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/qm283mxc\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/qm283mxc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: ltb0yu2c with config:\n",
      "wandb: \tbeam_size: 1\n",
      "wandb: \tcell_type: GRU\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_size: 64\n",
      "wandb: \tinput_embed_size: 64\n",
      "wandb: \tnum_decoder_layers: 1\n",
      "wandb: \tnum_encoder_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wild-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/sweeps/h9nur1ze\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/sweeps/h9nur1ze</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/ltb0yu2c\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/ltb0yu2c</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210508_212204-ltb0yu2c</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check2\n",
      "check3\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\h9nur1ze\\wild-sweep-2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\h9nur1ze\\wild-sweep-2\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 27776<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210508_212204-ltb0yu2c\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\HP\\Documents\\DL\\RecurrentNetwork\\wandb\\run-20210508_212204-ltb0yu2c\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>0.0</td></tr><tr><td>_runtime</td><td>78</td></tr><tr><td>_timestamp</td><td>1620489203</td></tr><tr><td>_step</td><td>0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_Acc</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wild-sweep-2</strong>: <a href=\"https://wandb.ai/mooizz/Rec_dakhashina/runs/ltb0yu2c\" target=\"_blank\">https://wandb.ai/mooizz/Rec_dakhashina/runs/ltb0yu2c</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32263abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
